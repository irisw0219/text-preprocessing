{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text data processing pipeline (Compiled)\n",
    "## by Iris and Pooja!\n",
    "\n",
    "### The following pipeline is considered:\n",
    "* Use of punctuation across labels: q_marks, exclamation marks\n",
    "* Use of multiple caps_lock words\n",
    "* POS tagged words - using adjectives (deleting nouns?)\n",
    "* Use of emojis across labels\n",
    "* Use of manual bigrams - in the form of adjective_noun for common vocabulary (specific to a label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import *\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import math\n",
    "from nltk.probability import *\n",
    "from gensim import corpora\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import re  # For preprocessing\n",
    "from collections import defaultdict  # For word frequency\n",
    "\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The new rule is - \\r\\nif you are waiting for a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flirted with giving this two stars, but that's...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was staying at planet Hollywood across the s...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Food is good but prices are super expensive.  ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Worse company to deal with they do horrible wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  The new rule is - \\r\\nif you are waiting for a...      4\n",
       "1  Flirted with giving this two stars, but that's...      3\n",
       "2  I was staying at planet Hollywood across the s...      5\n",
       "3  Food is good but prices are super expensive.  ...      2\n",
       "4  Worse company to deal with they do horrible wo...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "labeled_data = pd.read_csv('./labeled_data.csv')\n",
    "\n",
    "# Have a look at the top 5 rows\n",
    "labeled_data.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>trying to have a nice quiet dinner.  the annou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Been getting food to go from here for over 3yr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ugh. I've had to eat here a couple of times be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The people here are so nice! I ordered on eat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard alot of good things about this place and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0    NaN  trying to have a nice quiet dinner.  the annou...\n",
       "1    NaN  Been getting food to go from here for over 3yr...\n",
       "2    NaN  Ugh. I've had to eat here a couple of times be...\n",
       "3    NaN  The people here are so nice! I ordered on eat ...\n",
       "4    NaN  Heard alot of good things about this place and..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import unlabeled data\n",
    "test_data  = pd.read_csv('./test_data.csv')\n",
    "unlabeled_data = pd.read_csv('./unlabeled_data.csv')\n",
    "\n",
    "# Combine all the data (for training the language model)\n",
    "all_data = pd.DataFrame(test_data['text']).append(labeled_data)\n",
    "\n",
    "# Check the length of the dataframe\n",
    "print(len(all_data))\n",
    "all_data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>trying to have a nice quiet dinner.  the annou...</td>\n",
       "      <td>trying to have a nice quiet dinner.  the annou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Been getting food to go from here for over 3yr...</td>\n",
       "      <td>been getting food to go from here for over 3yr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ugh. I've had to eat here a couple of times be...</td>\n",
       "      <td>ugh. i've had to eat here a couple of times be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The people here are so nice! I ordered on eat ...</td>\n",
       "      <td>the people here are so nice! i ordered on eat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard alot of good things about this place and...</td>\n",
       "      <td>heard alot of good things about this place and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0    NaN  trying to have a nice quiet dinner.  the annou...   \n",
       "1    NaN  Been getting food to go from here for over 3yr...   \n",
       "2    NaN  Ugh. I've had to eat here a couple of times be...   \n",
       "3    NaN  The people here are so nice! I ordered on eat ...   \n",
       "4    NaN  Heard alot of good things about this place and...   \n",
       "\n",
       "                                      text_processed  \n",
       "0  trying to have a nice quiet dinner.  the annou...  \n",
       "1  been getting food to go from here for over 3yr...  \n",
       "2  ugh. i've had to eat here a couple of times be...  \n",
       "3  the people here are so nice! i ordered on eat ...  \n",
       "4  heard alot of good things about this place and...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contractions = { \n",
    "    \"ain't\": \"not\",\n",
    "    \"aren't\": \"not\",\n",
    "    \"arent\": \"not\",\n",
    "    \"can't\": \"not\",\n",
    "    \"cant\": \"not\",\n",
    "    \"can't've\": \"not\",\n",
    "    \"couldn't\": \"not\",\n",
    "    \"couldnt\": \"not\",\n",
    "    \"couldn't've\": \"not\",\n",
    "    \"didn't\": \"not\",\n",
    "    \"didnt\": \"not\",\n",
    "    \"doesn't\": \"not\",\n",
    "    \"doesnt\": \"not\",\n",
    "    \"don't\": \"not\",\n",
    "    \"dont\": \"not\",\n",
    "    \"hadn't\": \"not\",\n",
    "    \"hadn't've\": \"not\",\n",
    "    \"hasn't\": \"not\",\n",
    "    \"haven't\": \"not\",\n",
    "    \"havent\": \"not\",\n",
    "    \"mayn't\": \"not\",\n",
    "    \"mightn't\": \"not\",\n",
    "    \"mightn't've\": \"not\",\n",
    "    \"must've\": \"\",\n",
    "    \"mustn't\": \"not\",\n",
    "    \"mustn't've\": \"not\",\n",
    "    \"needn't\": \"not\",\n",
    "    \"needn't've\": \"not\",\n",
    "    \"oughtn't\": \"not\",\n",
    "    \"oughtn't've\": \"not\",\n",
    "    \"shan't\": \"not\",\n",
    "    \"sha'n't\": \"not\",\n",
    "    \"shan't've\": \"not\",\n",
    "    \"shouldn't\": \"not\",\n",
    "    \"shouldn't've\": \"not\",\n",
    "    \"won't\": \"not\",\n",
    "    \"wont\": \"not\",\n",
    "    \"won't've\": \"not\",\n",
    "    \"cause\": \"because\",\n",
    "    \"wouldn't\": \"not\",\n",
    "    \"wouldnt\": \"not\",\n",
    "    \"wouldn't've\": \"not\"\n",
    "}\n",
    "\n",
    "\n",
    "stars = {\n",
    "    '[\\b\\s]10/10':'amazing',\n",
    "    '\\b5\\.\\b':'amazing',\n",
    "    '10 star[s]?':'amazing',\n",
    "    '[56789] star[s]?':'amazing',\n",
    "    'five star[s]?':'amazing',\n",
    "    'four star[s]?':'great',\n",
    "    '\\b4\\.\\b':'great',\n",
    "    '4 star[s]?':'great',\n",
    "    '4-star[s]?':'great',\n",
    "    '4\\.[0-9]+ star[s]?':'great',\n",
    "    'was a 4':'great',\n",
    "    '4.5/5':'great',\n",
    "    '4/5':'great',\n",
    "    'three star[s]?':'average',\n",
    "    '3 star[s]?':'average',\n",
    "    '\\b3\\.\\b':'average',\n",
    "    '3-star[s]?':'average',\n",
    "    '3\\.[0-9]+ star[s]?':'average',\n",
    "    'was a 3':'average',\n",
    "    '3.5/5':'average',\n",
    "    '3/5':'average',\n",
    "    'two star[s]?':'bad',\n",
    "    '\\b2\\.\\b':'bad',\n",
    "    '2 star[s]?':'bad',\n",
    "    '2-star[s]?':'bad',\n",
    "    '2\\.[0-9]+ star[s]?':'bad',\n",
    "    'was a 2':'bad',\n",
    "    '2.5/5':'bad',\n",
    "    '2/5':'bad',\n",
    "    '\\b1\\.\\b':'bad',\n",
    "    '1 star[s]?':'horrible',\n",
    "    '1-star[s]?':'horrible',\n",
    "    '0 star[s]?':'horrible',\n",
    "    '0-star[s]?':'horrible',\n",
    "    'no star[s]?':'horrible',\n",
    "    'one star[s]?':'horrible',\n",
    "    'zero star[s]?':'horrible',\n",
    "    'negative star[s]?':'horrible'\n",
    "}\n",
    "\n",
    "\n",
    "irregular_spellings = {\n",
    "    'ÃÂ©':'e',# fixing this non-ascii value\n",
    "    r'(\\bam[mazing]+g\\b)':'amazing',\n",
    "    r'(\\bg[o]{2,}d\\b)':'good',\n",
    "    r'(yu[um]+[omyers!]+)':'yummy',\n",
    "    r'(w+[ay]{1,}y)':'way',\n",
    "    r'(over\\s?r?ated)':'overrated',\n",
    "    r'([!]{2,})':' absolute ',\n",
    "    r'([?]{1,}[?!]*)':' why ',\n",
    "    r'([!]{2,})':' absolute ',\n",
    "    r'([?]{1,}[?!]*)':' why '\n",
    "}\n",
    "\n",
    "\n",
    "# case normalization\n",
    "all_data['text_processed']= all_data['text'].str.lower()\n",
    "# replace starts related ngrams with adj's\n",
    "for mention, repl in stars.items():\n",
    "    all_data.text_processed = all_data.text_processed.str.replace(mention, repl)\n",
    "# replace negating contractions with 'not'\n",
    "for contr, repl in contractions.items():\n",
    "    all_data.text_processed = all_data.text_processed.str.replace(contr, repl)\n",
    "# replace negating contractions with 'not'\n",
    "for irregular, repl in irregular_spellings.items():\n",
    "    all_data.text_processed = all_data.text_processed.str.replace(irregular, repl)\n",
    "    \n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS TO DO PRE-PROCESSING\n",
    "\n",
    "# removing non-alphabets\n",
    "def remove_characters(comment):\n",
    "    comment = re.sub(r\"[^A-Za-z]+\", ' ', str(comment)).lower()\n",
    "    return comment\n",
    "\n",
    "# tokenize each comment\n",
    "def tokenize(comment):\n",
    "    tokenizer = RegexpTokenizer(r\"\\s+\", gaps=True)\n",
    "    return tokenizer.tokenize(comment)\n",
    "\n",
    "# remove stopwords\n",
    "keep = ['not','no','but','because','into','above','below','up',\\\n",
    "        'down','again','further','why','how','more','most','all','any','such',\\\n",
    "        'very','too','so','just','by']\n",
    "add = ['could','would']\n",
    "stopwords_list = stopwords.words('english') + add\n",
    "stopwords_list = [w for w in stopwords_list if w not in keep]\n",
    "def remove_stopwords(tokens_list):\n",
    "    return [x for x in tokens_list if x not in stopwords_list]\n",
    "\n",
    "# stemming\n",
    "stemmer = SnowballStemmer('english')\n",
    "def stem_words(tokens_list):\n",
    "    return [stemmer.stem(x) for x in tokens_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>trying to have a nice quiet dinner.  the annou...</td>\n",
       "      <td>trying to have a nice quiet dinner the announc...</td>\n",
       "      <td>[trying, nice, quiet, dinner, announcer, award...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Been getting food to go from here for over 3yr...</td>\n",
       "      <td>been getting food to go from here for over yrs...</td>\n",
       "      <td>[getting, food, go, yrs, wife, usually, tend, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ugh. I've had to eat here a couple of times be...</td>\n",
       "      <td>ugh i ve had to eat here a couple of times beb...</td>\n",
       "      <td>[ugh, eat, couple, times, bebecause, work, eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The people here are so nice! I ordered on eat ...</td>\n",
       "      <td>the people here are so nice i ordered on eat a...</td>\n",
       "      <td>[people, so, nice, ordered, eat, promptly, cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard alot of good things about this place and...</td>\n",
       "      <td>heard alot of good things about this place and...</td>\n",
       "      <td>[heard, alot, good, things, place, decided, gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0    NaN  trying to have a nice quiet dinner.  the annou...   \n",
       "1    NaN  Been getting food to go from here for over 3yr...   \n",
       "2    NaN  Ugh. I've had to eat here a couple of times be...   \n",
       "3    NaN  The people here are so nice! I ordered on eat ...   \n",
       "4    NaN  Heard alot of good things about this place and...   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  trying to have a nice quiet dinner the announc...   \n",
       "1  been getting food to go from here for over yrs...   \n",
       "2  ugh i ve had to eat here a couple of times beb...   \n",
       "3  the people here are so nice i ordered on eat a...   \n",
       "4  heard alot of good things about this place and...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [trying, nice, quiet, dinner, announcer, award...  \n",
       "1  [getting, food, go, yrs, wife, usually, tend, ...  \n",
       "2  [ugh, eat, couple, times, bebecause, work, eve...  \n",
       "3  [people, so, nice, ordered, eat, promptly, cal...  \n",
       "4  [heard, alot, good, things, place, decided, gr...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove some kinds of characters characters\n",
    "all_data[\"text_processed\"] = all_data[\"text_processed\"].apply(remove_characters)\n",
    "\n",
    "# tokenize the data\n",
    "all_data[\"tokens\"] = all_data.text_processed.apply(tokenize)\n",
    "\n",
    "# remove stop-words from tokens list\n",
    "all_data.tokens = all_data.tokens.apply(remove_stopwords)\n",
    "\n",
    "# view the processed data and tokens\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>trying to have a nice quiet dinner.  the annou...</td>\n",
       "      <td>trying to have a nice quiet dinner the announc...</td>\n",
       "      <td>[trying, nice, quiet, dinner, announcer, award...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Been getting food to go from here for over 3yr...</td>\n",
       "      <td>been getting food to go from here for over yrs...</td>\n",
       "      <td>[getting, food, go, yrs, wife, usually, tend, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ugh. I've had to eat here a couple of times be...</td>\n",
       "      <td>ugh i ve had to eat here a couple of times beb...</td>\n",
       "      <td>[ugh, eat, couple, times, bebecause, work, eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The people here are so nice! I ordered on eat ...</td>\n",
       "      <td>the people here are so nice i ordered on eat a...</td>\n",
       "      <td>[people, so, nice, ordered, eat, promptly, cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard alot of good things about this place and...</td>\n",
       "      <td>heard alot of good things about this place and...</td>\n",
       "      <td>[heard, alot, good, things, place, decided, gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0    NaN  trying to have a nice quiet dinner.  the annou...   \n",
       "1    NaN  Been getting food to go from here for over 3yr...   \n",
       "2    NaN  Ugh. I've had to eat here a couple of times be...   \n",
       "3    NaN  The people here are so nice! I ordered on eat ...   \n",
       "4    NaN  Heard alot of good things about this place and...   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  trying to have a nice quiet dinner the announc...   \n",
       "1  been getting food to go from here for over yrs...   \n",
       "2  ugh i ve had to eat here a couple of times beb...   \n",
       "3  the people here are so nice i ordered on eat a...   \n",
       "4  heard alot of good things about this place and...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [trying, nice, quiet, dinner, announcer, award...  \n",
       "1  [getting, food, go, yrs, wife, usually, tend, ...  \n",
       "2  [ugh, eat, couple, times, bebecause, work, eve...  \n",
       "3  [people, so, nice, ordered, eat, promptly, cal...  \n",
       "4  [heard, alot, good, things, place, decided, gr...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = all_data.reset_index(drop=True)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26091</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ç¾å³ããã£ãã¼ï¼ï¼</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28298</th>\n",
       "      <td>NaN</td>\n",
       "      <td>èæ¿å¾ç­æ",
       "ï¼è¯´æè¯ä»·çå­æ°å°æä...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37800</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6å ä¸æ¹æµ·é²é",
       "å®¶çå¹²ççæ²³ ç»åç...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42313</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5å å¹²ççæ²³ é",
       "èæ¯è¾ä¹±ä¸å",
       "«ç³ é...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47029</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ä»å¤©çèè²å¤±æï¼å»å¸«æ²ç¨å¿ï¼å",
       "¨æ...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51491</th>\n",
       "      <td>1.0</td>\n",
       "      <td>......</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54323</th>\n",
       "      <td>3.0</td>\n",
       "      <td>ï¼ãæåãã¾ããï¼å¤§å¥½ãã§ãã\\...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62644</th>\n",
       "      <td>4.0</td>\n",
       "      <td>éè »å¥½åçï¼åªæ¯é",
       "¸è¾£æ¹¯åºæå¯ä»¥å...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76397</th>\n",
       "      <td>2.0</td>\n",
       "      <td>ä¹",
       "ãã¶ãã«å£ã«åããªãï¼\\r\\nã¹ã¢...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79785</th>\n",
       "      <td>2.0</td>\n",
       "      <td>;))</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "26091    NaN                        ç¾å³ããã£ãã¼ï¼ï¼   \n",
       "28298    NaN  èæ¿å¾ç­æ\n",
       "ï¼è¯´æè¯ä»·çå­æ°å°æä...   \n",
       "37800    NaN  6å ä¸æ¹æµ·é²é\n",
       "å®¶çå¹²ççæ²³ ç»åç...   \n",
       "42313    NaN  5.5å å¹²ççæ²³ é\n",
       "èæ¯è¾ä¹±ä¸å\n",
       "«ç³ é...   \n",
       "47029    NaN  ä»å¤©çèè²å¤±æï¼å»å¸«æ²ç¨å¿ï¼å\n",
       "¨æ...   \n",
       "51491    1.0                                             ......   \n",
       "54323    3.0  ï¼ãæåãã¾ããï¼å¤§å¥½ãã§ãã\\...   \n",
       "62644    4.0  éè »å¥½åçï¼åªæ¯é\n",
       "¸è¾£æ¹¯åºæå¯ä»¥å...   \n",
       "76397    2.0  ä¹\n",
       "ãã¶ãã«å£ã«åããªãï¼\\r\\nã¹ã¢...   \n",
       "79785    2.0                                                ;))   \n",
       "\n",
       "      text_processed tokens  \n",
       "26091                    []  \n",
       "28298                    []  \n",
       "37800                    []  \n",
       "42313                    []  \n",
       "47029                    []  \n",
       "51491                    []  \n",
       "54323                    []  \n",
       "62644                    []  \n",
       "76397                    []  \n",
       "79785                    []  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine and impute rows in df with empty lists in them\n",
    "no_tokens = list(all_data.loc[(all_data['tokens'].str.len() == 0), :].index)\n",
    "all_data.loc[no_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tagged</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>no_nouns</th>\n",
       "      <th>no_nouns_stemmed</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26091</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ç¾å³ããã£ãã¼ï¼ï¼</td>\n",
       "      <td></td>\n",
       "      <td>hmm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28298</th>\n",
       "      <td>NaN</td>\n",
       "      <td>èæ¿å¾ç­æ",
       "ï¼è¯´æè¯ä»·çå­æ°å°æä...</td>\n",
       "      <td></td>\n",
       "      <td>hmm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37800</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6å ä¸æ¹æµ·é²é",
       "å®¶çå¹²ççæ²³ ç»åç...</td>\n",
       "      <td></td>\n",
       "      <td>hmm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42313</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5å å¹²ççæ²³ é",
       "èæ¯è¾ä¹±ä¸å",
       "«ç³ é...</td>\n",
       "      <td></td>\n",
       "      <td>hmm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47029</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ä»å¤©çèè²å¤±æï¼å»å¸«æ²ç¨å¿ï¼å",
       "¨æ...</td>\n",
       "      <td></td>\n",
       "      <td>hmm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51491</th>\n",
       "      <td>1.0</td>\n",
       "      <td>......</td>\n",
       "      <td></td>\n",
       "      <td>hmm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54323</th>\n",
       "      <td>3.0</td>\n",
       "      <td>ï¼ãæåãã¾ããï¼å¤§å¥½ãã§ãã\\...</td>\n",
       "      <td></td>\n",
       "      <td>hmm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62644</th>\n",
       "      <td>4.0</td>\n",
       "      <td>éè »å¥½åçï¼åªæ¯é",
       "¸è¾£æ¹¯åºæå¯ä»¥å...</td>\n",
       "      <td></td>\n",
       "      <td>hmm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76397</th>\n",
       "      <td>2.0</td>\n",
       "      <td>ä¹",
       "ãã¶ãã«å£ã«åããªãï¼\\r\\nã¹ã¢...</td>\n",
       "      <td></td>\n",
       "      <td>hmm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79785</th>\n",
       "      <td>2.0</td>\n",
       "      <td>;))</td>\n",
       "      <td></td>\n",
       "      <td>hmm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "26091    NaN                        ç¾å³ããã£ãã¼ï¼ï¼   \n",
       "28298    NaN  èæ¿å¾ç­æ\n",
       "ï¼è¯´æè¯ä»·çå­æ°å°æä...   \n",
       "37800    NaN  6å ä¸æ¹æµ·é²é\n",
       "å®¶çå¹²ççæ²³ ç»åç...   \n",
       "42313    NaN  5.5å å¹²ççæ²³ é\n",
       "èæ¯è¾ä¹±ä¸å\n",
       "«ç³ é...   \n",
       "47029    NaN  ä»å¤©çèè²å¤±æï¼å»å¸«æ²ç¨å¿ï¼å\n",
       "¨æ...   \n",
       "51491    1.0                                             ......   \n",
       "54323    3.0  ï¼ãæåãã¾ããï¼å¤§å¥½ãã§ãã\\...   \n",
       "62644    4.0  éè »å¥½åçï¼åªæ¯é\n",
       "¸è¾£æ¹¯åºæå¯ä»¥å...   \n",
       "76397    2.0  ä¹\n",
       "ãã¶ãã«å£ã«åããªãï¼\\r\\nã¹ã¢...   \n",
       "79785    2.0                                                ;))   \n",
       "\n",
       "      text_processed tokens pos_tagged adjectives nouns no_nouns  \\\n",
       "26091                   hmm         []         []    []       []   \n",
       "28298                   hmm         []         []    []       []   \n",
       "37800                   hmm         []         []    []       []   \n",
       "42313                   hmm         []         []    []       []   \n",
       "47029                   hmm         []         []    []       []   \n",
       "51491                   hmm         []         []    []       []   \n",
       "54323                   hmm         []         []    []       []   \n",
       "62644                   hmm         []         []    []       []   \n",
       "76397                   hmm         []         []    []       []   \n",
       "79785                   hmm         []         []    []       []   \n",
       "\n",
       "      no_nouns_stemmed tokens_stemmed  \n",
       "26091               []             []  \n",
       "28298               []             []  \n",
       "37800               []             []  \n",
       "42313               []             []  \n",
       "47029               []             []  \n",
       "51491               []             []  \n",
       "54323               []             []  \n",
       "62644               []             []  \n",
       "76397               []             []  \n",
       "79785               []             []  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.loc[no_tokens,'tokens'] = 'hmm'\n",
    "all_data.loc[no_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Label-Wise EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Looking at Commonly Used POSpeech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS-Tagging the Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using nltk to pos-tag\n",
    "#def pos_tagger(token_list):\n",
    " #   return nltk.pos_tag([x for x in token_list if x])\n",
    "\n",
    "all_data[\"pos_tagged\"] = all_data.tokens.apply(nltk.pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function to tag using \"pos\" and filter tokens from df.tokens list of tokens\n",
    "# for example, finding the adjectives as below\n",
    "pos = \"JJ+\"\n",
    "\n",
    "def POS(token_pos_list):\n",
    "    return [x[0] for x in token_pos_list if re.search(pos, x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tagged</th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>trying to have a nice quiet dinner.  the annou...</td>\n",
       "      <td>trying to have a nice quiet dinner the announc...</td>\n",
       "      <td>[trying, nice, quiet, dinner, announcer, award...</td>\n",
       "      <td>[(trying, VBG), (nice, JJ), (quiet, JJ), (dinn...</td>\n",
       "      <td>[nice, quiet, loud]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Been getting food to go from here for over 3yr...</td>\n",
       "      <td>been getting food to go from here for over yrs...</td>\n",
       "      <td>[getting, food, go, yrs, wife, usually, tend, ...</td>\n",
       "      <td>[(getting, VBG), (food, NN), (go, VB), (yrs, J...</td>\n",
       "      <td>[yrs, mongolian, special, noodle, best, chines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ugh. I've had to eat here a couple of times be...</td>\n",
       "      <td>ugh i ve had to eat here a couple of times beb...</td>\n",
       "      <td>[ugh, eat, couple, times, bebecause, work, eve...</td>\n",
       "      <td>[(ugh, JJ), (eat, NN), (couple, NN), (times, N...</td>\n",
       "      <td>[ugh, clad, super, much, salad, sure, helpful,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The people here are so nice! I ordered on eat ...</td>\n",
       "      <td>the people here are so nice i ordered on eat a...</td>\n",
       "      <td>[people, so, nice, ordered, eat, promptly, cal...</td>\n",
       "      <td>[(people, NNS), (so, RB), (nice, JJ), (ordered...</td>\n",
       "      <td>[nice, double, sweet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard alot of good things about this place and...</td>\n",
       "      <td>heard alot of good things about this place and...</td>\n",
       "      <td>[heard, alot, good, things, place, decided, gr...</td>\n",
       "      <td>[(heard, NN), (alot, NN), (good, JJ), (things,...</td>\n",
       "      <td>[good, cheese, large, hungry, hot, green, def]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0    NaN  trying to have a nice quiet dinner.  the annou...   \n",
       "1    NaN  Been getting food to go from here for over 3yr...   \n",
       "2    NaN  Ugh. I've had to eat here a couple of times be...   \n",
       "3    NaN  The people here are so nice! I ordered on eat ...   \n",
       "4    NaN  Heard alot of good things about this place and...   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  trying to have a nice quiet dinner the announc...   \n",
       "1  been getting food to go from here for over yrs...   \n",
       "2  ugh i ve had to eat here a couple of times beb...   \n",
       "3  the people here are so nice i ordered on eat a...   \n",
       "4  heard alot of good things about this place and...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [trying, nice, quiet, dinner, announcer, award...   \n",
       "1  [getting, food, go, yrs, wife, usually, tend, ...   \n",
       "2  [ugh, eat, couple, times, bebecause, work, eve...   \n",
       "3  [people, so, nice, ordered, eat, promptly, cal...   \n",
       "4  [heard, alot, good, things, place, decided, gr...   \n",
       "\n",
       "                                          pos_tagged  \\\n",
       "0  [(trying, VBG), (nice, JJ), (quiet, JJ), (dinn...   \n",
       "1  [(getting, VBG), (food, NN), (go, VB), (yrs, J...   \n",
       "2  [(ugh, JJ), (eat, NN), (couple, NN), (times, N...   \n",
       "3  [(people, NNS), (so, RB), (nice, JJ), (ordered...   \n",
       "4  [(heard, NN), (alot, NN), (good, JJ), (things,...   \n",
       "\n",
       "                                          adjectives  \n",
       "0                                [nice, quiet, loud]  \n",
       "1  [yrs, mongolian, special, noodle, best, chines...  \n",
       "2  [ugh, clad, super, much, salad, sure, helpful,...  \n",
       "3                              [nice, double, sweet]  \n",
       "4     [good, cheese, large, hungry, hot, green, def]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding all adjectives for the labels\n",
    "all_data[\"adjectives\"] = all_data.pos_tagged.apply(POS)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NN*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tagged</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>trying to have a nice quiet dinner.  the annou...</td>\n",
       "      <td>trying to have a nice quiet dinner the announc...</td>\n",
       "      <td>[trying, nice, quiet, dinner, announcer, award...</td>\n",
       "      <td>[(trying, VBG), (nice, JJ), (quiet, JJ), (dinn...</td>\n",
       "      <td>[nice, quiet, loud]</td>\n",
       "      <td>[dinner, announcer, awards, way, restaurant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Been getting food to go from here for over 3yr...</td>\n",
       "      <td>been getting food to go from here for over yrs...</td>\n",
       "      <td>[getting, food, go, yrs, wife, usually, tend, ...</td>\n",
       "      <td>[(getting, VBG), (food, NN), (go, VB), (yrs, J...</td>\n",
       "      <td>[yrs, mongolian, special, noodle, best, chines...</td>\n",
       "      <td>[food, wife, items, something, works, beef, lu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ugh. I've had to eat here a couple of times be...</td>\n",
       "      <td>ugh i ve had to eat here a couple of times beb...</td>\n",
       "      <td>[ugh, eat, couple, times, bebecause, work, eve...</td>\n",
       "      <td>[(ugh, JJ), (eat, NN), (couple, NN), (times, N...</td>\n",
       "      <td>[ugh, clad, super, much, salad, sure, helpful,...</td>\n",
       "      <td>[eat, couple, times, work, events, course, gir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The people here are so nice! I ordered on eat ...</td>\n",
       "      <td>the people here are so nice i ordered on eat a...</td>\n",
       "      <td>[people, so, nice, ordered, eat, promptly, cal...</td>\n",
       "      <td>[(people, NNS), (so, RB), (nice, JJ), (ordered...</td>\n",
       "      <td>[nice, double, sweet]</td>\n",
       "      <td>[people, eat, check, everything]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard alot of good things about this place and...</td>\n",
       "      <td>heard alot of good things about this place and...</td>\n",
       "      <td>[heard, alot, good, things, place, decided, gr...</td>\n",
       "      <td>[(heard, NN), (alot, NN), (good, JJ), (things,...</td>\n",
       "      <td>[good, cheese, large, hungry, hot, green, def]</td>\n",
       "      <td>[heard, alot, things, place, grab, breakfast, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0    NaN  trying to have a nice quiet dinner.  the annou...   \n",
       "1    NaN  Been getting food to go from here for over 3yr...   \n",
       "2    NaN  Ugh. I've had to eat here a couple of times be...   \n",
       "3    NaN  The people here are so nice! I ordered on eat ...   \n",
       "4    NaN  Heard alot of good things about this place and...   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  trying to have a nice quiet dinner the announc...   \n",
       "1  been getting food to go from here for over yrs...   \n",
       "2  ugh i ve had to eat here a couple of times beb...   \n",
       "3  the people here are so nice i ordered on eat a...   \n",
       "4  heard alot of good things about this place and...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [trying, nice, quiet, dinner, announcer, award...   \n",
       "1  [getting, food, go, yrs, wife, usually, tend, ...   \n",
       "2  [ugh, eat, couple, times, bebecause, work, eve...   \n",
       "3  [people, so, nice, ordered, eat, promptly, cal...   \n",
       "4  [heard, alot, good, things, place, decided, gr...   \n",
       "\n",
       "                                          pos_tagged  \\\n",
       "0  [(trying, VBG), (nice, JJ), (quiet, JJ), (dinn...   \n",
       "1  [(getting, VBG), (food, NN), (go, VB), (yrs, J...   \n",
       "2  [(ugh, JJ), (eat, NN), (couple, NN), (times, N...   \n",
       "3  [(people, NNS), (so, RB), (nice, JJ), (ordered...   \n",
       "4  [(heard, NN), (alot, NN), (good, JJ), (things,...   \n",
       "\n",
       "                                          adjectives  \\\n",
       "0                                [nice, quiet, loud]   \n",
       "1  [yrs, mongolian, special, noodle, best, chines...   \n",
       "2  [ugh, clad, super, much, salad, sure, helpful,...   \n",
       "3                              [nice, double, sweet]   \n",
       "4     [good, cheese, large, hungry, hot, green, def]   \n",
       "\n",
       "                                               nouns  \n",
       "0       [dinner, announcer, awards, way, restaurant]  \n",
       "1  [food, wife, items, something, works, beef, lu...  \n",
       "2  [eat, couple, times, work, events, course, gir...  \n",
       "3                   [people, eat, check, everything]  \n",
       "4  [heard, alot, things, place, grab, breakfast, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  finding all the nouns\n",
    "pos = \"NN\"\n",
    "all_data[\"nouns\"] = all_data.pos_tagged.apply(POS)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tagged</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>no_nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>trying to have a nice quiet dinner.  the annou...</td>\n",
       "      <td>trying to have a nice quiet dinner the announc...</td>\n",
       "      <td>[trying, nice, quiet, dinner, announcer, award...</td>\n",
       "      <td>[(trying, VBG), (nice, JJ), (quiet, JJ), (dinn...</td>\n",
       "      <td>[nice, quiet, loud]</td>\n",
       "      <td>[dinner, announcer, awards, way, restaurant]</td>\n",
       "      <td>[trying, nice, quiet, giveaways, too, loud]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Been getting food to go from here for over 3yr...</td>\n",
       "      <td>been getting food to go from here for over yrs...</td>\n",
       "      <td>[getting, food, go, yrs, wife, usually, tend, ...</td>\n",
       "      <td>[(getting, VBG), (food, NN), (go, VB), (yrs, J...</td>\n",
       "      <td>[yrs, mongolian, special, noodle, best, chines...</td>\n",
       "      <td>[food, wife, items, something, works, beef, lu...</td>\n",
       "      <td>[getting, go, yrs, usually, tend, get, why, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ugh. I've had to eat here a couple of times be...</td>\n",
       "      <td>ugh i ve had to eat here a couple of times beb...</td>\n",
       "      <td>[ugh, eat, couple, times, bebecause, work, eve...</td>\n",
       "      <td>[(ugh, JJ), (eat, NN), (couple, NN), (times, N...</td>\n",
       "      <td>[ugh, clad, super, much, salad, sure, helpful,...</td>\n",
       "      <td>[eat, couple, times, work, events, course, gir...</td>\n",
       "      <td>[ugh, bebecause, makes, snotily, clad, super, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The people here are so nice! I ordered on eat ...</td>\n",
       "      <td>the people here are so nice i ordered on eat a...</td>\n",
       "      <td>[people, so, nice, ordered, eat, promptly, cal...</td>\n",
       "      <td>[(people, NNS), (so, RB), (nice, JJ), (ordered...</td>\n",
       "      <td>[nice, double, sweet]</td>\n",
       "      <td>[people, eat, check, everything]</td>\n",
       "      <td>[so, nice, ordered, promptly, called, double, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard alot of good things about this place and...</td>\n",
       "      <td>heard alot of good things about this place and...</td>\n",
       "      <td>[heard, alot, good, things, place, decided, gr...</td>\n",
       "      <td>[(heard, NN), (alot, NN), (good, JJ), (things,...</td>\n",
       "      <td>[good, cheese, large, hungry, hot, green, def]</td>\n",
       "      <td>[heard, alot, things, place, grab, breakfast, ...</td>\n",
       "      <td>[good, decided, say, enjoyed, cheese, firstly,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0    NaN  trying to have a nice quiet dinner.  the annou...   \n",
       "1    NaN  Been getting food to go from here for over 3yr...   \n",
       "2    NaN  Ugh. I've had to eat here a couple of times be...   \n",
       "3    NaN  The people here are so nice! I ordered on eat ...   \n",
       "4    NaN  Heard alot of good things about this place and...   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  trying to have a nice quiet dinner the announc...   \n",
       "1  been getting food to go from here for over yrs...   \n",
       "2  ugh i ve had to eat here a couple of times beb...   \n",
       "3  the people here are so nice i ordered on eat a...   \n",
       "4  heard alot of good things about this place and...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [trying, nice, quiet, dinner, announcer, award...   \n",
       "1  [getting, food, go, yrs, wife, usually, tend, ...   \n",
       "2  [ugh, eat, couple, times, bebecause, work, eve...   \n",
       "3  [people, so, nice, ordered, eat, promptly, cal...   \n",
       "4  [heard, alot, good, things, place, decided, gr...   \n",
       "\n",
       "                                          pos_tagged  \\\n",
       "0  [(trying, VBG), (nice, JJ), (quiet, JJ), (dinn...   \n",
       "1  [(getting, VBG), (food, NN), (go, VB), (yrs, J...   \n",
       "2  [(ugh, JJ), (eat, NN), (couple, NN), (times, N...   \n",
       "3  [(people, NNS), (so, RB), (nice, JJ), (ordered...   \n",
       "4  [(heard, NN), (alot, NN), (good, JJ), (things,...   \n",
       "\n",
       "                                          adjectives  \\\n",
       "0                                [nice, quiet, loud]   \n",
       "1  [yrs, mongolian, special, noodle, best, chines...   \n",
       "2  [ugh, clad, super, much, salad, sure, helpful,...   \n",
       "3                              [nice, double, sweet]   \n",
       "4     [good, cheese, large, hungry, hot, green, def]   \n",
       "\n",
       "                                               nouns  \\\n",
       "0       [dinner, announcer, awards, way, restaurant]   \n",
       "1  [food, wife, items, something, works, beef, lu...   \n",
       "2  [eat, couple, times, work, events, course, gir...   \n",
       "3                   [people, eat, check, everything]   \n",
       "4  [heard, alot, things, place, grab, breakfast, ...   \n",
       "\n",
       "                                            no_nouns  \n",
       "0        [trying, nice, quiet, giveaways, too, loud]  \n",
       "1  [getting, go, yrs, usually, tend, get, why, fi...  \n",
       "2  [ugh, bebecause, makes, snotily, clad, super, ...  \n",
       "3  [so, nice, ordered, promptly, called, double, ...  \n",
       "4  [good, decided, say, enjoyed, cheese, firstly,...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecsub = lambda x, y: [item for item in x if item not in y]\n",
    "all_data['no_nouns'] = list(map(vecsub, all_data['tokens'], all_data['nouns']))\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tagged</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>no_nouns</th>\n",
       "      <th>no_nouns_stemmed</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>trying to have a nice quiet dinner.  the annou...</td>\n",
       "      <td>trying to have a nice quiet dinner the announc...</td>\n",
       "      <td>[trying, nice, quiet, dinner, announcer, award...</td>\n",
       "      <td>[(trying, VBG), (nice, JJ), (quiet, JJ), (dinn...</td>\n",
       "      <td>[nice, quiet, loud]</td>\n",
       "      <td>[dinner, announcer, awards, way, restaurant]</td>\n",
       "      <td>[trying, nice, quiet, giveaways, too, loud]</td>\n",
       "      <td>[tri, nice, quiet, giveaway, too, loud]</td>\n",
       "      <td>[tri, nice, quiet, dinner, announc, award, giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Been getting food to go from here for over 3yr...</td>\n",
       "      <td>been getting food to go from here for over yrs...</td>\n",
       "      <td>[getting, food, go, yrs, wife, usually, tend, ...</td>\n",
       "      <td>[(getting, VBG), (food, NN), (go, VB), (yrs, J...</td>\n",
       "      <td>[yrs, mongolian, special, noodle, best, chines...</td>\n",
       "      <td>[food, wife, items, something, works, beef, lu...</td>\n",
       "      <td>[getting, go, yrs, usually, tend, get, why, fi...</td>\n",
       "      <td>[get, go, yrs, usual, tend, get, whi, fix, alw...</td>\n",
       "      <td>[get, food, go, yrs, wife, usual, tend, get, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ugh. I've had to eat here a couple of times be...</td>\n",
       "      <td>ugh i ve had to eat here a couple of times beb...</td>\n",
       "      <td>[ugh, eat, couple, times, bebecause, work, eve...</td>\n",
       "      <td>[(ugh, JJ), (eat, NN), (couple, NN), (times, N...</td>\n",
       "      <td>[ugh, clad, super, much, salad, sure, helpful,...</td>\n",
       "      <td>[eat, couple, times, work, events, course, gir...</td>\n",
       "      <td>[ugh, bebecause, makes, snotily, clad, super, ...</td>\n",
       "      <td>[ugh, bebecaus, make, snotili, clad, super, aw...</td>\n",
       "      <td>[ugh, eat, coupl, time, bebecaus, work, event,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The people here are so nice! I ordered on eat ...</td>\n",
       "      <td>the people here are so nice i ordered on eat a...</td>\n",
       "      <td>[people, so, nice, ordered, eat, promptly, cal...</td>\n",
       "      <td>[(people, NNS), (so, RB), (nice, JJ), (ordered...</td>\n",
       "      <td>[nice, double, sweet]</td>\n",
       "      <td>[people, eat, check, everything]</td>\n",
       "      <td>[so, nice, ordered, promptly, called, double, ...</td>\n",
       "      <td>[so, nice, order, prompt, call, doubl, correct...</td>\n",
       "      <td>[peopl, so, nice, order, eat, prompt, call, do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard alot of good things about this place and...</td>\n",
       "      <td>heard alot of good things about this place and...</td>\n",
       "      <td>[heard, alot, good, things, place, decided, gr...</td>\n",
       "      <td>[(heard, NN), (alot, NN), (good, JJ), (things,...</td>\n",
       "      <td>[good, cheese, large, hungry, hot, green, def]</td>\n",
       "      <td>[heard, alot, things, place, grab, breakfast, ...</td>\n",
       "      <td>[good, decided, say, enjoyed, cheese, firstly,...</td>\n",
       "      <td>[good, decid, say, enjoy, chees, first, rather...</td>\n",
       "      <td>[heard, alot, good, thing, place, decid, grab,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0    NaN  trying to have a nice quiet dinner.  the annou...   \n",
       "1    NaN  Been getting food to go from here for over 3yr...   \n",
       "2    NaN  Ugh. I've had to eat here a couple of times be...   \n",
       "3    NaN  The people here are so nice! I ordered on eat ...   \n",
       "4    NaN  Heard alot of good things about this place and...   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  trying to have a nice quiet dinner the announc...   \n",
       "1  been getting food to go from here for over yrs...   \n",
       "2  ugh i ve had to eat here a couple of times beb...   \n",
       "3  the people here are so nice i ordered on eat a...   \n",
       "4  heard alot of good things about this place and...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [trying, nice, quiet, dinner, announcer, award...   \n",
       "1  [getting, food, go, yrs, wife, usually, tend, ...   \n",
       "2  [ugh, eat, couple, times, bebecause, work, eve...   \n",
       "3  [people, so, nice, ordered, eat, promptly, cal...   \n",
       "4  [heard, alot, good, things, place, decided, gr...   \n",
       "\n",
       "                                          pos_tagged  \\\n",
       "0  [(trying, VBG), (nice, JJ), (quiet, JJ), (dinn...   \n",
       "1  [(getting, VBG), (food, NN), (go, VB), (yrs, J...   \n",
       "2  [(ugh, JJ), (eat, NN), (couple, NN), (times, N...   \n",
       "3  [(people, NNS), (so, RB), (nice, JJ), (ordered...   \n",
       "4  [(heard, NN), (alot, NN), (good, JJ), (things,...   \n",
       "\n",
       "                                          adjectives  \\\n",
       "0                                [nice, quiet, loud]   \n",
       "1  [yrs, mongolian, special, noodle, best, chines...   \n",
       "2  [ugh, clad, super, much, salad, sure, helpful,...   \n",
       "3                              [nice, double, sweet]   \n",
       "4     [good, cheese, large, hungry, hot, green, def]   \n",
       "\n",
       "                                               nouns  \\\n",
       "0       [dinner, announcer, awards, way, restaurant]   \n",
       "1  [food, wife, items, something, works, beef, lu...   \n",
       "2  [eat, couple, times, work, events, course, gir...   \n",
       "3                   [people, eat, check, everything]   \n",
       "4  [heard, alot, things, place, grab, breakfast, ...   \n",
       "\n",
       "                                            no_nouns  \\\n",
       "0        [trying, nice, quiet, giveaways, too, loud]   \n",
       "1  [getting, go, yrs, usually, tend, get, why, fi...   \n",
       "2  [ugh, bebecause, makes, snotily, clad, super, ...   \n",
       "3  [so, nice, ordered, promptly, called, double, ...   \n",
       "4  [good, decided, say, enjoyed, cheese, firstly,...   \n",
       "\n",
       "                                    no_nouns_stemmed  \\\n",
       "0            [tri, nice, quiet, giveaway, too, loud]   \n",
       "1  [get, go, yrs, usual, tend, get, whi, fix, alw...   \n",
       "2  [ugh, bebecaus, make, snotili, clad, super, aw...   \n",
       "3  [so, nice, order, prompt, call, doubl, correct...   \n",
       "4  [good, decid, say, enjoy, chees, first, rather...   \n",
       "\n",
       "                                      tokens_stemmed  \n",
       "0  [tri, nice, quiet, dinner, announc, award, giv...  \n",
       "1  [get, food, go, yrs, wife, usual, tend, get, i...  \n",
       "2  [ugh, eat, coupl, time, bebecaus, work, event,...  \n",
       "3  [peopl, so, nice, order, eat, prompt, call, do...  \n",
       "4  [heard, alot, good, thing, place, decid, grab,...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stem the tokens\n",
    "all_data['no_nouns_stemmed'] = all_data.no_nouns.apply(stem_words)\n",
    "all_data['tokens_stemmed'] = all_data.tokens.apply(stem_words)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Triigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(not, go, back)</td>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(not, come, back)</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(good, but, not)</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(never, go, back)</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(definit, come, back)</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(food, good, but)</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(not, know, how)</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(come, back, again)</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(staff, veri, friend)</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(definit, go, back)</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(go, back, again)</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(mac, n, chees)</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(go, somewher, els)</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(great, custom, servic)</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(not, so, much)</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(pretti, good, but)</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(not, wast, time)</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(not, recommend, place)</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(not, sure, whi)</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(but, just, not)</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0     1\n",
       "0           (not, go, back)  1379\n",
       "1         (not, come, back)   870\n",
       "2          (good, but, not)   867\n",
       "3         (never, go, back)   660\n",
       "4     (definit, come, back)   645\n",
       "5         (food, good, but)   564\n",
       "6          (not, know, how)   557\n",
       "7       (come, back, again)   530\n",
       "8     (staff, veri, friend)   497\n",
       "9       (definit, go, back)   495\n",
       "10        (go, back, again)   480\n",
       "11          (mac, n, chees)   404\n",
       "12      (go, somewher, els)   403\n",
       "13  (great, custom, servic)   389\n",
       "14          (not, so, much)   389\n",
       "15      (pretti, good, but)   385\n",
       "16        (not, wast, time)   379\n",
       "17  (not, recommend, place)   373\n",
       "18         (not, sure, whi)   362\n",
       "19         (but, just, not)   362"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check common bigrams for \"not_good\" appearing a lot more\n",
    "tokens_list = [item for sublist in list(all_data.tokens_stemmed) for item in sublist]\n",
    "fd = FreqDist(tokens_list)\n",
    "\n",
    "# most common tokens - document frequency\n",
    "trigrams = ngrams(tokens_list, n = 3)\n",
    "fdtrigram = FreqDist(trigrams)\n",
    "trigrams = fdtrigram.most_common()\n",
    "trigrams = pd.DataFrame(trigrams)#.set_index(0)\n",
    "trigrams[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep trigrams with freq > 300\n",
    "top_trigrams = trigrams[trigrams.loc[:,1]>300].loc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not go back': 'not_go_back',\n",
       " 'not come back': 'not_come_back',\n",
       " 'good but not': 'good_but_not',\n",
       " 'never go back': 'never_go_back',\n",
       " 'definit come back': 'definit_come_back',\n",
       " 'food good but': 'food_good_but',\n",
       " 'not know how': 'not_know_how',\n",
       " 'come back again': 'come_back_again',\n",
       " 'staff veri friend': 'staff_veri_friend',\n",
       " 'definit go back': 'definit_go_back',\n",
       " 'go back again': 'go_back_again',\n",
       " 'mac n chees': 'mac_n_chees',\n",
       " 'go somewher els': 'go_somewher_els',\n",
       " 'great custom servic': 'great_custom_servic',\n",
       " 'not so much': 'not_so_much',\n",
       " 'pretti good but': 'pretti_good_but',\n",
       " 'not wast time': 'not_wast_time',\n",
       " 'not recommend place': 'not_recommend_place',\n",
       " 'not sure whi': 'not_sure_whi',\n",
       " 'but just not': 'but_just_not',\n",
       " 'sweet potato fri': 'sweet_potato_fri',\n",
       " 'way too much': 'way_too_much',\n",
       " 'not feel like': 'not_feel_like',\n",
       " 'but not go': 'but_not_go',\n",
       " 'food pretti good': 'food_pretti_good',\n",
       " 'never come back': 'never_come_back',\n",
       " 'not get wrong': 'not_get_wrong',\n",
       " 'not veri good': 'not_veri_good',\n",
       " 'not know whi': 'not_know_whi',\n",
       " 'come back tri': 'come_back_tri',\n",
       " 'go back tri': 'go_back_tri',\n",
       " 'food veri good': 'food_veri_good',\n",
       " 'but not great': 'but_not_great'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findTrigrams = {}\n",
    "for tg in top_trigrams:\n",
    "    key = tg[0]+\" \"+tg[1]+\" \"+tg[2]\n",
    "    findTrigrams[key] = tg[0]+\"_\"+tg[1]+\"_\"+tg[2]\n",
    "\n",
    "findTrigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(but, not)</td>\n",
       "      <td>11816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(go, back)</td>\n",
       "      <td>6610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(custom, servic)</td>\n",
       "      <td>6137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(come, back)</td>\n",
       "      <td>6055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(not, even)</td>\n",
       "      <td>5491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(first, time)</td>\n",
       "      <td>4474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(not, go)</td>\n",
       "      <td>4418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(not, know)</td>\n",
       "      <td>4297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(good, but)</td>\n",
       "      <td>4282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(veri, good)</td>\n",
       "      <td>4278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(not, get)</td>\n",
       "      <td>4239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(end, up)</td>\n",
       "      <td>3753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(so, not)</td>\n",
       "      <td>3689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(pick, up)</td>\n",
       "      <td>3396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(pretti, good)</td>\n",
       "      <td>3271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(not, want)</td>\n",
       "      <td>3097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(look, like)</td>\n",
       "      <td>3082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(just, not)</td>\n",
       "      <td>3037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(realli, good)</td>\n",
       "      <td>2926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(not, sure)</td>\n",
       "      <td>2883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(so, much)</td>\n",
       "      <td>2872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(ice, cream)</td>\n",
       "      <td>2742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(not, like)</td>\n",
       "      <td>2723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(veri, nice)</td>\n",
       "      <td>2681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(even, though)</td>\n",
       "      <td>2643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(no, one)</td>\n",
       "      <td>2591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(tast, like)</td>\n",
       "      <td>2582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(high, recommend)</td>\n",
       "      <td>2530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(feel, like)</td>\n",
       "      <td>2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(next, time)</td>\n",
       "      <td>2499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0      1\n",
       "0          (but, not)  11816\n",
       "1          (go, back)   6610\n",
       "2    (custom, servic)   6137\n",
       "3        (come, back)   6055\n",
       "4         (not, even)   5491\n",
       "5       (first, time)   4474\n",
       "6           (not, go)   4418\n",
       "7         (not, know)   4297\n",
       "8         (good, but)   4282\n",
       "9        (veri, good)   4278\n",
       "10         (not, get)   4239\n",
       "11          (end, up)   3753\n",
       "12          (so, not)   3689\n",
       "13         (pick, up)   3396\n",
       "14     (pretti, good)   3271\n",
       "15        (not, want)   3097\n",
       "16       (look, like)   3082\n",
       "17        (just, not)   3037\n",
       "18     (realli, good)   2926\n",
       "19        (not, sure)   2883\n",
       "20         (so, much)   2872\n",
       "21       (ice, cream)   2742\n",
       "22        (not, like)   2723\n",
       "23       (veri, nice)   2681\n",
       "24     (even, though)   2643\n",
       "25          (no, one)   2591\n",
       "26       (tast, like)   2582\n",
       "27  (high, recommend)   2530\n",
       "28       (feel, like)   2502\n",
       "29       (next, time)   2499"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common tokens - document frequency\n",
    "bigrams = ngrams(tokens_list, n = 2)\n",
    "fdbigram = FreqDist(bigrams)\n",
    "bigrams = fdbigram.most_common()\n",
    "bigrams = pd.DataFrame(bigrams)\n",
    "bigrams[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('but', 'not'),\n",
       " ('go', 'back'),\n",
       " ('custom', 'servic'),\n",
       " ('come', 'back'),\n",
       " ('not', 'even'),\n",
       " ('first', 'time'),\n",
       " ('not', 'go'),\n",
       " ('not', 'know'),\n",
       " ('good', 'but'),\n",
       " ('veri', 'good'),\n",
       " ('not', 'get'),\n",
       " ('end', 'up'),\n",
       " ('so', 'not'),\n",
       " ('pick', 'up'),\n",
       " ('pretti', 'good'),\n",
       " ('not', 'want'),\n",
       " ('look', 'like'),\n",
       " ('just', 'not'),\n",
       " ('realli', 'good'),\n",
       " ('not', 'sure'),\n",
       " ('so', 'much'),\n",
       " ('ice', 'cream'),\n",
       " ('not', 'like'),\n",
       " ('veri', 'nice'),\n",
       " ('even', 'though'),\n",
       " ('no', 'one'),\n",
       " ('tast', 'like'),\n",
       " ('high', 'recommend'),\n",
       " ('feel', 'like'),\n",
       " ('next', 'time'),\n",
       " ('whi', 'not'),\n",
       " ('food', 'good'),\n",
       " ('not', 'realli'),\n",
       " ('make', 'sure'),\n",
       " ('not', 'good'),\n",
       " ('too', 'much'),\n",
       " ('las', 'vega'),\n",
       " ('not', 'think'),\n",
       " ('not', 'come'),\n",
       " ('veri', 'friend'),\n",
       " ('everi', 'time'),\n",
       " ('seem', 'like'),\n",
       " ('food', 'not'),\n",
       " ('happi', 'hour'),\n",
       " ('good', 'food'),\n",
       " ('but', 'still'),\n",
       " ('bebecaus', 'not'),\n",
       " ('so', 'mani'),\n",
       " ('not', 'recommend'),\n",
       " ('so', 'good'),\n",
       " ('not', 'worth'),\n",
       " ('great', 'place'),\n",
       " ('not', 'too'),\n",
       " ('place', 'not'),\n",
       " ('not', 'bad'),\n",
       " ('last', 'time'),\n",
       " ('much', 'better'),\n",
       " ('love', 'place'),\n",
       " ('great', 'servic'),\n",
       " ('servic', 'great'),\n",
       " ('not', 'care'),\n",
       " ('show', 'up'),\n",
       " ('but', 'just'),\n",
       " ('wait', 'minut'),\n",
       " ('food', 'great'),\n",
       " ('not', 'so'),\n",
       " ('great', 'food'),\n",
       " ('not', 'veri'),\n",
       " ('definit', 'not'),\n",
       " ('way', 'too'),\n",
       " ('good', 'servic'),\n",
       " ('not', 'wait'),\n",
       " ('long', 'time'),\n",
       " ('food', 'but'),\n",
       " ('back', 'again'),\n",
       " ('came', 'back'),\n",
       " ('not', 'great'),\n",
       " ('place', 'go'),\n",
       " ('veri', 'disappoint'),\n",
       " ('felt', 'like'),\n",
       " ('not', 'return'),\n",
       " ('place', 'but'),\n",
       " ('servic', 'good'),\n",
       " ('front', 'desk'),\n",
       " ('realli', 'like'),\n",
       " ('know', 'how'),\n",
       " ('recommend', 'place'),\n",
       " ('all', 'all'),\n",
       " ('but', 'no'),\n",
       " ('said', 'not'),\n",
       " ('not', 'make'),\n",
       " ('great', 'but'),\n",
       " ('but', 'food'),\n",
       " ('time', 'not'),\n",
       " ('good', 'not'),\n",
       " ('not', 'back'),\n",
       " ('last', 'night'),\n",
       " ('servic', 'not'),\n",
       " ('noth', 'special'),\n",
       " ('not', 'give'),\n",
       " ('pretti', 'much'),\n",
       " ('not', 'eat'),\n",
       " ('year', 'ago'),\n",
       " ('not', 'much'),\n",
       " ('realli', 'not'),\n",
       " ('not', 'say'),\n",
       " ('call', 'back'),\n",
       " ('told', 'us'),\n",
       " ('stop', 'by'),\n",
       " ('not', 'see'),\n",
       " ('not', 'take'),\n",
       " ('probabl', 'not'),\n",
       " ('still', 'not'),\n",
       " ('reason', 'price'),\n",
       " ('next', 'day'),\n",
       " ('food', 'servic'),\n",
       " ('not', 'seem'),\n",
       " ('not', 'order'),\n",
       " ('look', 'forward'),\n",
       " ('tri', 'place'),\n",
       " ('not', 'expect'),\n",
       " ('fri', 'rice'),\n",
       " ('staff', 'veri'),\n",
       " ('but', 'realli'),\n",
       " ('qualiti', 'food'),\n",
       " ('one', 'best'),\n",
       " ('good', 'thing'),\n",
       " ('like', 'not'),\n",
       " ('park', 'lot'),\n",
       " ('never', 'go'),\n",
       " ('right', 'away'),\n",
       " ('but', 'noth'),\n",
       " ('take', 'order'),\n",
       " ('give', 'place'),\n",
       " ('year', 'old'),\n",
       " ('minut', 'later'),\n",
       " ('all', 'time'),\n",
       " ('fast', 'food'),\n",
       " ('realli', 'enjoy'),\n",
       " ('but', 'servic'),\n",
       " ('but', 'never'),\n",
       " ('good', 'place'),\n",
       " ('fri', 'chicken'),\n",
       " ('gave', 'us'),\n",
       " ('time', 'but'),\n",
       " ('say', 'not'),\n",
       " ('realli', 'nice'),\n",
       " ('like', 'place'),\n",
       " ('mac', 'chees'),\n",
       " ('staff', 'friend'),\n",
       " ('told', 'not'),\n",
       " ('place', 'order'),\n",
       " ('not', 'feel'),\n",
       " ('set', 'up'),\n",
       " ('but', 'definit'),\n",
       " ('second', 'time'),\n",
       " ('ok', 'but'),\n",
       " ('not', 'work'),\n",
       " ('want', 'tri'),\n",
       " ('credit', 'card'),\n",
       " ('just', 'want'),\n",
       " ('not', 'ani'),\n",
       " ('not', 'disappoint'),\n",
       " ('went', 'back'),\n",
       " ('place', 'so'),\n",
       " ('time', 'go'),\n",
       " ('sever', 'time'),\n",
       " ('but', 'also'),\n",
       " ('not', 'tri'),\n",
       " ('more', 'like'),\n",
       " ('how', 'much'),\n",
       " ('so', 'far'),\n",
       " ('too', 'bad'),\n",
       " ('nice', 'but'),\n",
       " ('just', 'ok'),\n",
       " ('not', 'find'),\n",
       " ('not', 'tast'),\n",
       " ('wait', 'staff'),\n",
       " ('realli', 'want'),\n",
       " ('somewher', 'els'),\n",
       " ('by', 'time'),\n",
       " ('servic', 'veri'),\n",
       " ('tri', 'get'),\n",
       " ('but', 'good'),\n",
       " ('littl', 'bit'),\n",
       " ('much', 'more'),\n",
       " ('get', 'food'),\n",
       " ('not', 'just'),\n",
       " ('order', 'food'),\n",
       " ('but', 'veri'),\n",
       " ('not', 'one'),\n",
       " ('friend', 'staff'),\n",
       " ('no', 'longer'),\n",
       " ('place', 'get'),\n",
       " ('place', 'great'),\n",
       " ('so', 'so'),\n",
       " ('go', 'again'),\n",
       " ('not', 'best'),\n",
       " ('wast', 'time'),\n",
       " ('great', 'experi'),\n",
       " ('also', 'not'),\n",
       " ('too', 'mani'),\n",
       " ('drink', 'order'),\n",
       " ('also', 'order'),\n",
       " ('food', 'came'),\n",
       " ('absolut', 'not'),\n",
       " ('veri', 'clean'),\n",
       " ('back', 'tri'),\n",
       " ('by', 'far'),\n",
       " ('mani', 'time'),\n",
       " ('not', 'use'),\n",
       " ('wait', 'time'),\n",
       " ('not', 'believ'),\n",
       " ('not', 'need'),\n",
       " ('food', 'veri'),\n",
       " ('mess', 'up'),\n",
       " ('one', 'thing'),\n",
       " ('said', 'no'),\n",
       " ('not', 'mind'),\n",
       " ('let', 'know'),\n",
       " ('not', 'impress'),\n",
       " ('not', 'all'),\n",
       " ('food', 'just'),\n",
       " ('no', 'idea'),\n",
       " ('food', 'so'),\n",
       " ('definit', 'recommend'),\n",
       " ('mexican', 'food'),\n",
       " ('time', 'went'),\n",
       " ('bad', 'but'),\n",
       " ('not', 'look'),\n",
       " ('so', 'decid'),\n",
       " ('best', 'part'),\n",
       " ('saturday', 'night'),\n",
       " ('sit', 'down'),\n",
       " ('also', 'veri'),\n",
       " ('but', 'one'),\n",
       " ('took', 'minut'),\n",
       " ('want', 'go'),\n",
       " ('but', 'all'),\n",
       " ('no', 'problem'),\n",
       " ('price', 'not'),\n",
       " ('time', 'get'),\n",
       " ('sweet', 'potato'),\n",
       " ('definit', 'back'),\n",
       " ('definit', 'come'),\n",
       " ('all', 'way'),\n",
       " ('littl', 'more'),\n",
       " ('walk', 'away'),\n",
       " ('not', 'enough'),\n",
       " ('order', 'chicken'),\n",
       " ('sat', 'down'),\n",
       " ('hot', 'dog'),\n",
       " ('veri', 'tasti'),\n",
       " ('friday', 'night'),\n",
       " ('long', 'wait'),\n",
       " ('food', 'order'),\n",
       " ('definit', 'go'),\n",
       " ('not', 'understand'),\n",
       " ('go', 'get'),\n",
       " ('veri', 'well'),\n",
       " ('ask', 'want'),\n",
       " ('pad', 'thai'),\n",
       " ('too', 'long'),\n",
       " ('servic', 'food'),\n",
       " ('around', 'pm'),\n",
       " ('restaur', 'not'),\n",
       " ('look', 'good'),\n",
       " ('good', 'price'),\n",
       " ('not', 'help'),\n",
       " ('across', 'street'),\n",
       " ('again', 'not'),\n",
       " ('up', 'order'),\n",
       " ('not', 'let'),\n",
       " ('wait', 'line'),\n",
       " ('not', 'bother'),\n",
       " ('walk', 'around'),\n",
       " ('super', 'friend'),\n",
       " ('great', 'job'),\n",
       " ('not', 'ask'),\n",
       " ('time', 'so'),\n",
       " ('one', 'favorit'),\n",
       " ('chines', 'food'),\n",
       " ('take', 'care'),\n",
       " ('thing', 'not'),\n",
       " ('ask', 'how'),\n",
       " ('drive', 'thru'),\n",
       " ('back', 'not'),\n",
       " ('peopl', 'not'),\n",
       " ('well', 'not'),\n",
       " ('someon', 'els'),\n",
       " ('not', 'mention'),\n",
       " ('food', 'drink'),\n",
       " ('stay', 'away'),\n",
       " ('time', 'come'),\n",
       " ('busi', 'but'),\n",
       " ('dine', 'experi'),\n",
       " ('just', 'like'),\n",
       " ('back', 'but'),\n",
       " ('tast', 'good'),\n",
       " ('next', 'door'),\n",
       " ('behind', 'counter'),\n",
       " ('portion', 'size'),\n",
       " ('first', 'visit'),\n",
       " ('veri', 'veri'),\n",
       " ('but', 'place'),\n",
       " ('needless', 'say'),\n",
       " ('prime', 'rib'),\n",
       " ('read', 'review'),\n",
       " ('place', 'just'),\n",
       " ('so', 'long'),\n",
       " ('dim', 'sum'),\n",
       " ('place', 'like'),\n",
       " ('but', 'think'),\n",
       " ('mash', 'potato'),\n",
       " ('go', 'place'),\n",
       " ('but', 'so'),\n",
       " ('decid', 'tri'),\n",
       " ('so', 'bad'),\n",
       " ('just', 'get'),\n",
       " ('all', 'food'),\n",
       " ('so', 'get'),\n",
       " ('right', 'whi'),\n",
       " ('time', 'order'),\n",
       " ('give', 'tri'),\n",
       " ('friend', 'help'),\n",
       " ('late', 'night'),\n",
       " ('friend', 'servic'),\n",
       " ('give', 'us'),\n",
       " ('whi', 'no'),\n",
       " ('great', 'price'),\n",
       " ('just', 'right'),\n",
       " ('anoth', 'minut'),\n",
       " ('french', 'toast'),\n",
       " ('big', 'deal'),\n",
       " ('absolut', 'love'),\n",
       " ('minut', 'wait'),\n",
       " ('final', 'got'),\n",
       " ('new', 'york'),\n",
       " ('so', 'went'),\n",
       " ('write', 'review'),\n",
       " ('order', 'not'),\n",
       " ('us', 'not'),\n",
       " ('everyth', 'els'),\n",
       " ('one', 'time'),\n",
       " ('experi', 'not'),\n",
       " ('whi', 'so'),\n",
       " ('not', 'wast'),\n",
       " ('realli', 'whi'),\n",
       " ('veri', 'help'),\n",
       " ('ice', 'tea'),\n",
       " ('bad', 'experi'),\n",
       " ('good', 'experi'),\n",
       " ('make', 'up'),\n",
       " ('place', 'eat'),\n",
       " ('bit', 'more'),\n",
       " ('all', 'day'),\n",
       " ('food', 'ok'),\n",
       " ('well', 'done'),\n",
       " ('cook', 'perfect'),\n",
       " ('sinc', 'not'),\n",
       " ('order', 'again'),\n",
       " ('oil', 'chang'),\n",
       " ('see', 'how'),\n",
       " ('but', 'get'),\n",
       " ('minut', 'get'),\n",
       " ('half', 'hour'),\n",
       " ('week', 'ago'),\n",
       " ('food', 'delici'),\n",
       " ('not', 'big'),\n",
       " ('so', 'just'),\n",
       " ('good', 'time'),\n",
       " ('fill', 'up'),\n",
       " ('wait', 'hour'),\n",
       " ('not', 'rememb'),\n",
       " ('so', 'call'),\n",
       " ('good', 'too'),\n",
       " ('decid', 'give'),\n",
       " ('phone', 'call'),\n",
       " ('know', 'whi'),\n",
       " ('all', 'not'),\n",
       " ('friend', 'but'),\n",
       " ('give', 'horribl'),\n",
       " ('friend', 'order'),\n",
       " ('walk', 'into'),\n",
       " ('mani', 'peopl'),\n",
       " ('help', 'us'),\n",
       " ('tri', 'again'),\n",
       " ('not', 'pay'),\n",
       " ('pull', 'pork'),\n",
       " ('crab', 'leg'),\n",
       " ('whi', 'whi'),\n",
       " ('last', 'week'),\n",
       " ('though', 'not'),\n",
       " ('decid', 'go'),\n",
       " ('make', 'feel'),\n",
       " ('so', 'nice'),\n",
       " ('fine', 'but'),\n",
       " ('veri', 'attent'),\n",
       " ('give', 'anoth'),\n",
       " ('veri', 'rude'),\n",
       " ('anyth', 'els'),\n",
       " ('coupl', 'time'),\n",
       " ('veri', 'small'),\n",
       " ('month', 'ago'),\n",
       " ('top', 'notch'),\n",
       " ('one', 'person'),\n",
       " ('follow', 'up'),\n",
       " ('place', 'veri'),\n",
       " ('want', 'get'),\n",
       " ('not', 'abl'),\n",
       " ('but', 'like'),\n",
       " ('review', 'but'),\n",
       " ('spring', 'roll'),\n",
       " ('food', 'pretti'),\n",
       " ('onion', 'ring'),\n",
       " ('too', 'sweet'),\n",
       " ('hot', 'sauc'),\n",
       " ('tell', 'us'),\n",
       " ('gluten', 'free'),\n",
       " ('hit', 'miss'),\n",
       " ('take', 'time'),\n",
       " ('bad', 'servic'),\n",
       " ('get', 'back'),\n",
       " ('someth', 'els'),\n",
       " ('so', 'ask'),\n",
       " ('food', 'qualiti'),\n",
       " ('just', 'go'),\n",
       " ('staff', 'not'),\n",
       " ('all', 'good'),\n",
       " ('bad', 'bebecaus'),\n",
       " ('nice', 'place'),\n",
       " ('not', 'tell'),\n",
       " ('no', 'way'),\n",
       " ('never', 'again'),\n",
       " ('get', 'drink'),\n",
       " ('restaur', 'but'),\n",
       " ('got', 'home'),\n",
       " ('time', 'tri'),\n",
       " ('just', 'okay'),\n",
       " ('veri', 'reason'),\n",
       " ('dine', 'room'),\n",
       " ('ask', 'whi'),\n",
       " ('so', 'no'),\n",
       " ('time', 'food'),\n",
       " ('last', 'year'),\n",
       " ('servic', 'friend'),\n",
       " ('chip', 'salsa'),\n",
       " ('lunch', 'special'),\n",
       " ('peopl', 'work'),\n",
       " ('so', 'order'),\n",
       " ('took', 'order'),\n",
       " ('all', 'eat'),\n",
       " ('up', 'not'),\n",
       " ('servic', 'but'),\n",
       " ('not', 'place'),\n",
       " ('food', 'realli'),\n",
       " ('menu', 'item'),\n",
       " ('but', 'again'),\n",
       " ('great', 'time'),\n",
       " ('know', 'not'),\n",
       " ('wait', 'min'),\n",
       " ('okay', 'but'),\n",
       " ('howev', 'not'),\n",
       " ('place', 'good'),\n",
       " ('veri', 'busi'),\n",
       " ('look', 'great'),\n",
       " ('first', 'all'),\n",
       " ('but', 'got'),\n",
       " ('amaz', 'but'),\n",
       " ('so', 'disappoint'),\n",
       " ('servic', 'excel'),\n",
       " ('alway', 'good'),\n",
       " ('so', 'go'),\n",
       " ('come', 'again'),\n",
       " ('one', 'day'),\n",
       " ('pleasant', 'surpris'),\n",
       " ('not', 'not'),\n",
       " ('food', 'place'),\n",
       " ('ask', 'us'),\n",
       " ('get', 'order'),\n",
       " ('greet', 'by'),\n",
       " ('abl', 'get'),\n",
       " ('food', 'alway'),\n",
       " ('groceri', 'store'),\n",
       " ('sign', 'up'),\n",
       " ('clean', 'up'),\n",
       " ('no', 'flavor'),\n",
       " ('littl', 'too'),\n",
       " ('down', 'street'),\n",
       " ('decent', 'but'),\n",
       " ('last', 'visit'),\n",
       " ('not', 'busi'),\n",
       " ('one', 'not'),\n",
       " ('check', 'us'),\n",
       " ('beer', 'select'),\n",
       " ('all', 'veri'),\n",
       " ('go', 'wrong'),\n",
       " ('veri', 'happi'),\n",
       " ('open', 'up'),\n",
       " ('go', 'somewher'),\n",
       " ('like', 'but'),\n",
       " ('hour', 'later'),\n",
       " ('tasti', 'but'),\n",
       " ('no', 'matter'),\n",
       " ('ok', 'not'),\n",
       " ('mayb', 'just'),\n",
       " ('hand', 'down'),\n",
       " ('place', 'realli'),\n",
       " ('french', 'fri'),\n",
       " ('bar', 'area'),\n",
       " ('food', 'amaz'),\n",
       " ('everi', 'singl'),\n",
       " ('three', 'time'),\n",
       " ('all', 'great'),\n",
       " ('place', 'tri'),\n",
       " ('took', 'forev'),\n",
       " ('friend', 'not'),\n",
       " ('made', 'feel'),\n",
       " ('just', 'so'),\n",
       " ('not', 'fan'),\n",
       " ('yelp', 'review'),\n",
       " ('even', 'more'),\n",
       " ('alway', 'get'),\n",
       " ('way', 'better'),\n",
       " ('up', 'get'),\n",
       " ('pork', 'belli'),\n",
       " ('no', 'not'),\n",
       " ('never', 'come'),\n",
       " ('long', 'line'),\n",
       " ('bebecaus', 'so'),\n",
       " ('order', 'drink'),\n",
       " ('how', 'mani'),\n",
       " ('day', 'later'),\n",
       " ('tri', 'someth'),\n",
       " ('price', 'reason'),\n",
       " ('recommend', 'anyon'),\n",
       " ('all', 'around'),\n",
       " ('also', 'got'),\n",
       " ('two', 'peopl'),\n",
       " ('more', 'time'),\n",
       " ('by', 'way'),\n",
       " ('multipl', 'time'),\n",
       " ('anywher', 'els'),\n",
       " ('deep', 'fri'),\n",
       " ('right', 'next'),\n",
       " ('best', 'thing'),\n",
       " ('not', 'quit'),\n",
       " ('time', 'just'),\n",
       " ('get', 'one'),\n",
       " ('more', 'expens'),\n",
       " ('servic', 'slow'),\n",
       " ('wait', 'food'),\n",
       " ('fish', 'taco'),\n",
       " ('car', 'wash'),\n",
       " ('carn', 'asada'),\n",
       " ('menu', 'not'),\n",
       " ('get', 'better'),\n",
       " ('realli', 'great'),\n",
       " ('made', 'sure'),\n",
       " ('how', 'long'),\n",
       " ('noodl', 'soup'),\n",
       " ('veri', 'much'),\n",
       " ('servic', 'alway'),\n",
       " ('chicken', 'sandwich'),\n",
       " ('price', 'but'),\n",
       " ('never', 'return'),\n",
       " ('just', 'got'),\n",
       " ('time', 'got'),\n",
       " ('give', 'bad'),\n",
       " ('per', 'person'),\n",
       " ('go', 'not'),\n",
       " ('by', 'say'),\n",
       " ('bad', 'review'),\n",
       " ('hard', 'find'),\n",
       " ('good', 'job'),\n",
       " ('servic', 'so'),\n",
       " ('food', 'court'),\n",
       " ('short', 'rib'),\n",
       " ('let', 'us'),\n",
       " ('tabl', 'not'),\n",
       " ('took', 'time')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bigrams = list(bigrams.loc[:,0])\n",
    "top = int(len(all_bigrams)*0.0003) \n",
    "top_bigrams = all_bigrams[:top]\n",
    "top_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'but not': 'but_not',\n",
       " 'go back': 'go_back',\n",
       " 'custom servic': 'custom_servic',\n",
       " 'come back': 'come_back',\n",
       " 'not even': 'not_even',\n",
       " 'first time': 'first_time',\n",
       " 'not go': 'not_go',\n",
       " 'not know': 'not_know',\n",
       " 'good but': 'good_but',\n",
       " 'veri good': 'veri_good',\n",
       " 'not get': 'not_get',\n",
       " 'end up': 'end_up',\n",
       " 'so not': 'so_not',\n",
       " 'pick up': 'pick_up',\n",
       " 'pretti good': 'pretti_good',\n",
       " 'not want': 'not_want',\n",
       " 'look like': 'look_like',\n",
       " 'just not': 'just_not',\n",
       " 'realli good': 'realli_good',\n",
       " 'not sure': 'not_sure',\n",
       " 'so much': 'so_much',\n",
       " 'ice cream': 'ice_cream',\n",
       " 'not like': 'not_like',\n",
       " 'veri nice': 'veri_nice',\n",
       " 'even though': 'even_though',\n",
       " 'no one': 'no_one',\n",
       " 'tast like': 'tast_like',\n",
       " 'high recommend': 'high_recommend',\n",
       " 'feel like': 'feel_like',\n",
       " 'next time': 'next_time',\n",
       " 'whi not': 'whi_not',\n",
       " 'food good': 'food_good',\n",
       " 'not realli': 'not_realli',\n",
       " 'make sure': 'make_sure',\n",
       " 'not good': 'not_good',\n",
       " 'too much': 'too_much',\n",
       " 'las vega': 'las_vega',\n",
       " 'not think': 'not_think',\n",
       " 'not come': 'not_come',\n",
       " 'veri friend': 'veri_friend',\n",
       " 'everi time': 'everi_time',\n",
       " 'seem like': 'seem_like',\n",
       " 'food not': 'food_not',\n",
       " 'happi hour': 'happi_hour',\n",
       " 'good food': 'good_food',\n",
       " 'but still': 'but_still',\n",
       " 'bebecaus not': 'bebecaus_not',\n",
       " 'so mani': 'so_mani',\n",
       " 'not recommend': 'not_recommend',\n",
       " 'so good': 'so_good',\n",
       " 'not worth': 'not_worth',\n",
       " 'great place': 'great_place',\n",
       " 'not too': 'not_too',\n",
       " 'place not': 'place_not',\n",
       " 'not bad': 'not_bad',\n",
       " 'last time': 'last_time',\n",
       " 'much better': 'much_better',\n",
       " 'love place': 'love_place',\n",
       " 'great servic': 'great_servic',\n",
       " 'servic great': 'servic_great',\n",
       " 'not care': 'not_care',\n",
       " 'show up': 'show_up',\n",
       " 'but just': 'but_just',\n",
       " 'wait minut': 'wait_minut',\n",
       " 'food great': 'food_great',\n",
       " 'not so': 'not_so',\n",
       " 'great food': 'great_food',\n",
       " 'not veri': 'not_veri',\n",
       " 'definit not': 'definit_not',\n",
       " 'way too': 'way_too',\n",
       " 'good servic': 'good_servic',\n",
       " 'not wait': 'not_wait',\n",
       " 'long time': 'long_time',\n",
       " 'food but': 'food_but',\n",
       " 'back again': 'back_again',\n",
       " 'came back': 'came_back',\n",
       " 'not great': 'not_great',\n",
       " 'place go': 'place_go',\n",
       " 'veri disappoint': 'veri_disappoint',\n",
       " 'felt like': 'felt_like',\n",
       " 'not return': 'not_return',\n",
       " 'place but': 'place_but',\n",
       " 'servic good': 'servic_good',\n",
       " 'front desk': 'front_desk',\n",
       " 'realli like': 'realli_like',\n",
       " 'know how': 'know_how',\n",
       " 'recommend place': 'recommend_place',\n",
       " 'all all': 'all_all',\n",
       " 'but no': 'but_no',\n",
       " 'said not': 'said_not',\n",
       " 'not make': 'not_make',\n",
       " 'great but': 'great_but',\n",
       " 'but food': 'but_food',\n",
       " 'time not': 'time_not',\n",
       " 'good not': 'good_not',\n",
       " 'not back': 'not_back',\n",
       " 'last night': 'last_night',\n",
       " 'servic not': 'servic_not',\n",
       " 'noth special': 'noth_special',\n",
       " 'not give': 'not_give',\n",
       " 'pretti much': 'pretti_much',\n",
       " 'not eat': 'not_eat',\n",
       " 'year ago': 'year_ago',\n",
       " 'not much': 'not_much',\n",
       " 'realli not': 'realli_not',\n",
       " 'not say': 'not_say',\n",
       " 'call back': 'call_back',\n",
       " 'told us': 'told_us',\n",
       " 'stop by': 'stop_by',\n",
       " 'not see': 'not_see',\n",
       " 'not take': 'not_take',\n",
       " 'probabl not': 'probabl_not',\n",
       " 'still not': 'still_not',\n",
       " 'reason price': 'reason_price',\n",
       " 'next day': 'next_day',\n",
       " 'food servic': 'food_servic',\n",
       " 'not seem': 'not_seem',\n",
       " 'not order': 'not_order',\n",
       " 'look forward': 'look_forward',\n",
       " 'tri place': 'tri_place',\n",
       " 'not expect': 'not_expect',\n",
       " 'fri rice': 'fri_rice',\n",
       " 'staff veri': 'staff_veri',\n",
       " 'but realli': 'but_realli',\n",
       " 'qualiti food': 'qualiti_food',\n",
       " 'one best': 'one_best',\n",
       " 'good thing': 'good_thing',\n",
       " 'like not': 'like_not',\n",
       " 'park lot': 'park_lot',\n",
       " 'never go': 'never_go',\n",
       " 'right away': 'right_away',\n",
       " 'but noth': 'but_noth',\n",
       " 'take order': 'take_order',\n",
       " 'give place': 'give_place',\n",
       " 'year old': 'year_old',\n",
       " 'minut later': 'minut_later',\n",
       " 'all time': 'all_time',\n",
       " 'fast food': 'fast_food',\n",
       " 'realli enjoy': 'realli_enjoy',\n",
       " 'but servic': 'but_servic',\n",
       " 'but never': 'but_never',\n",
       " 'good place': 'good_place',\n",
       " 'fri chicken': 'fri_chicken',\n",
       " 'gave us': 'gave_us',\n",
       " 'time but': 'time_but',\n",
       " 'say not': 'say_not',\n",
       " 'realli nice': 'realli_nice',\n",
       " 'like place': 'like_place',\n",
       " 'mac chees': 'mac_chees',\n",
       " 'staff friend': 'staff_friend',\n",
       " 'told not': 'told_not',\n",
       " 'place order': 'place_order',\n",
       " 'not feel': 'not_feel',\n",
       " 'set up': 'set_up',\n",
       " 'but definit': 'but_definit',\n",
       " 'second time': 'second_time',\n",
       " 'ok but': 'ok_but',\n",
       " 'not work': 'not_work',\n",
       " 'want tri': 'want_tri',\n",
       " 'credit card': 'credit_card',\n",
       " 'just want': 'just_want',\n",
       " 'not ani': 'not_ani',\n",
       " 'not disappoint': 'not_disappoint',\n",
       " 'went back': 'went_back',\n",
       " 'place so': 'place_so',\n",
       " 'time go': 'time_go',\n",
       " 'sever time': 'sever_time',\n",
       " 'but also': 'but_also',\n",
       " 'not tri': 'not_tri',\n",
       " 'more like': 'more_like',\n",
       " 'how much': 'how_much',\n",
       " 'so far': 'so_far',\n",
       " 'too bad': 'too_bad',\n",
       " 'nice but': 'nice_but',\n",
       " 'just ok': 'just_ok',\n",
       " 'not find': 'not_find',\n",
       " 'not tast': 'not_tast',\n",
       " 'wait staff': 'wait_staff',\n",
       " 'realli want': 'realli_want',\n",
       " 'somewher els': 'somewher_els',\n",
       " 'by time': 'by_time',\n",
       " 'servic veri': 'servic_veri',\n",
       " 'tri get': 'tri_get',\n",
       " 'but good': 'but_good',\n",
       " 'littl bit': 'littl_bit',\n",
       " 'much more': 'much_more',\n",
       " 'get food': 'get_food',\n",
       " 'not just': 'not_just',\n",
       " 'order food': 'order_food',\n",
       " 'but veri': 'but_veri',\n",
       " 'not one': 'not_one',\n",
       " 'friend staff': 'friend_staff',\n",
       " 'no longer': 'no_longer',\n",
       " 'place get': 'place_get',\n",
       " 'place great': 'place_great',\n",
       " 'so so': 'so_so',\n",
       " 'go again': 'go_again',\n",
       " 'not best': 'not_best',\n",
       " 'wast time': 'wast_time',\n",
       " 'great experi': 'great_experi',\n",
       " 'also not': 'also_not',\n",
       " 'too mani': 'too_mani',\n",
       " 'drink order': 'drink_order',\n",
       " 'also order': 'also_order',\n",
       " 'food came': 'food_came',\n",
       " 'absolut not': 'absolut_not',\n",
       " 'veri clean': 'veri_clean',\n",
       " 'back tri': 'back_tri',\n",
       " 'by far': 'by_far',\n",
       " 'mani time': 'mani_time',\n",
       " 'not use': 'not_use',\n",
       " 'wait time': 'wait_time',\n",
       " 'not believ': 'not_believ',\n",
       " 'not need': 'not_need',\n",
       " 'food veri': 'food_veri',\n",
       " 'mess up': 'mess_up',\n",
       " 'one thing': 'one_thing',\n",
       " 'said no': 'said_no',\n",
       " 'not mind': 'not_mind',\n",
       " 'let know': 'let_know',\n",
       " 'not impress': 'not_impress',\n",
       " 'not all': 'not_all',\n",
       " 'food just': 'food_just',\n",
       " 'no idea': 'no_idea',\n",
       " 'food so': 'food_so',\n",
       " 'definit recommend': 'definit_recommend',\n",
       " 'mexican food': 'mexican_food',\n",
       " 'time went': 'time_went',\n",
       " 'bad but': 'bad_but',\n",
       " 'not look': 'not_look',\n",
       " 'so decid': 'so_decid',\n",
       " 'best part': 'best_part',\n",
       " 'saturday night': 'saturday_night',\n",
       " 'sit down': 'sit_down',\n",
       " 'also veri': 'also_veri',\n",
       " 'but one': 'but_one',\n",
       " 'took minut': 'took_minut',\n",
       " 'want go': 'want_go',\n",
       " 'but all': 'but_all',\n",
       " 'no problem': 'no_problem',\n",
       " 'price not': 'price_not',\n",
       " 'time get': 'time_get',\n",
       " 'sweet potato': 'sweet_potato',\n",
       " 'definit back': 'definit_back',\n",
       " 'definit come': 'definit_come',\n",
       " 'all way': 'all_way',\n",
       " 'littl more': 'littl_more',\n",
       " 'walk away': 'walk_away',\n",
       " 'not enough': 'not_enough',\n",
       " 'order chicken': 'order_chicken',\n",
       " 'sat down': 'sat_down',\n",
       " 'hot dog': 'hot_dog',\n",
       " 'veri tasti': 'veri_tasti',\n",
       " 'friday night': 'friday_night',\n",
       " 'long wait': 'long_wait',\n",
       " 'food order': 'food_order',\n",
       " 'definit go': 'definit_go',\n",
       " 'not understand': 'not_understand',\n",
       " 'go get': 'go_get',\n",
       " 'veri well': 'veri_well',\n",
       " 'ask want': 'ask_want',\n",
       " 'pad thai': 'pad_thai',\n",
       " 'too long': 'too_long',\n",
       " 'servic food': 'servic_food',\n",
       " 'around pm': 'around_pm',\n",
       " 'restaur not': 'restaur_not',\n",
       " 'look good': 'look_good',\n",
       " 'good price': 'good_price',\n",
       " 'not help': 'not_help',\n",
       " 'across street': 'across_street',\n",
       " 'again not': 'again_not',\n",
       " 'up order': 'up_order',\n",
       " 'not let': 'not_let',\n",
       " 'wait line': 'wait_line',\n",
       " 'not bother': 'not_bother',\n",
       " 'walk around': 'walk_around',\n",
       " 'super friend': 'super_friend',\n",
       " 'great job': 'great_job',\n",
       " 'not ask': 'not_ask',\n",
       " 'time so': 'time_so',\n",
       " 'one favorit': 'one_favorit',\n",
       " 'chines food': 'chines_food',\n",
       " 'take care': 'take_care',\n",
       " 'thing not': 'thing_not',\n",
       " 'ask how': 'ask_how',\n",
       " 'drive thru': 'drive_thru',\n",
       " 'back not': 'back_not',\n",
       " 'peopl not': 'peopl_not',\n",
       " 'well not': 'well_not',\n",
       " 'someon els': 'someon_els',\n",
       " 'not mention': 'not_mention',\n",
       " 'food drink': 'food_drink',\n",
       " 'stay away': 'stay_away',\n",
       " 'time come': 'time_come',\n",
       " 'busi but': 'busi_but',\n",
       " 'dine experi': 'dine_experi',\n",
       " 'just like': 'just_like',\n",
       " 'back but': 'back_but',\n",
       " 'tast good': 'tast_good',\n",
       " 'next door': 'next_door',\n",
       " 'behind counter': 'behind_counter',\n",
       " 'portion size': 'portion_size',\n",
       " 'first visit': 'first_visit',\n",
       " 'veri veri': 'veri_veri',\n",
       " 'but place': 'but_place',\n",
       " 'needless say': 'needless_say',\n",
       " 'prime rib': 'prime_rib',\n",
       " 'read review': 'read_review',\n",
       " 'place just': 'place_just',\n",
       " 'so long': 'so_long',\n",
       " 'dim sum': 'dim_sum',\n",
       " 'place like': 'place_like',\n",
       " 'but think': 'but_think',\n",
       " 'mash potato': 'mash_potato',\n",
       " 'go place': 'go_place',\n",
       " 'but so': 'but_so',\n",
       " 'decid tri': 'decid_tri',\n",
       " 'so bad': 'so_bad',\n",
       " 'just get': 'just_get',\n",
       " 'all food': 'all_food',\n",
       " 'so get': 'so_get',\n",
       " 'right whi': 'right_whi',\n",
       " 'time order': 'time_order',\n",
       " 'give tri': 'give_tri',\n",
       " 'friend help': 'friend_help',\n",
       " 'late night': 'late_night',\n",
       " 'friend servic': 'friend_servic',\n",
       " 'give us': 'give_us',\n",
       " 'whi no': 'whi_no',\n",
       " 'great price': 'great_price',\n",
       " 'just right': 'just_right',\n",
       " 'anoth minut': 'anoth_minut',\n",
       " 'french toast': 'french_toast',\n",
       " 'big deal': 'big_deal',\n",
       " 'absolut love': 'absolut_love',\n",
       " 'minut wait': 'minut_wait',\n",
       " 'final got': 'final_got',\n",
       " 'new york': 'new_york',\n",
       " 'so went': 'so_went',\n",
       " 'write review': 'write_review',\n",
       " 'order not': 'order_not',\n",
       " 'us not': 'us_not',\n",
       " 'everyth els': 'everyth_els',\n",
       " 'one time': 'one_time',\n",
       " 'experi not': 'experi_not',\n",
       " 'whi so': 'whi_so',\n",
       " 'not wast': 'not_wast',\n",
       " 'realli whi': 'realli_whi',\n",
       " 'veri help': 'veri_help',\n",
       " 'ice tea': 'ice_tea',\n",
       " 'bad experi': 'bad_experi',\n",
       " 'good experi': 'good_experi',\n",
       " 'make up': 'make_up',\n",
       " 'place eat': 'place_eat',\n",
       " 'bit more': 'bit_more',\n",
       " 'all day': 'all_day',\n",
       " 'food ok': 'food_ok',\n",
       " 'well done': 'well_done',\n",
       " 'cook perfect': 'cook_perfect',\n",
       " 'sinc not': 'sinc_not',\n",
       " 'order again': 'order_again',\n",
       " 'oil chang': 'oil_chang',\n",
       " 'see how': 'see_how',\n",
       " 'but get': 'but_get',\n",
       " 'minut get': 'minut_get',\n",
       " 'half hour': 'half_hour',\n",
       " 'week ago': 'week_ago',\n",
       " 'food delici': 'food_delici',\n",
       " 'not big': 'not_big',\n",
       " 'so just': 'so_just',\n",
       " 'good time': 'good_time',\n",
       " 'fill up': 'fill_up',\n",
       " 'wait hour': 'wait_hour',\n",
       " 'not rememb': 'not_rememb',\n",
       " 'so call': 'so_call',\n",
       " 'good too': 'good_too',\n",
       " 'decid give': 'decid_give',\n",
       " 'phone call': 'phone_call',\n",
       " 'know whi': 'know_whi',\n",
       " 'all not': 'all_not',\n",
       " 'friend but': 'friend_but',\n",
       " 'give horribl': 'give_horribl',\n",
       " 'friend order': 'friend_order',\n",
       " 'walk into': 'walk_into',\n",
       " 'mani peopl': 'mani_peopl',\n",
       " 'help us': 'help_us',\n",
       " 'tri again': 'tri_again',\n",
       " 'not pay': 'not_pay',\n",
       " 'pull pork': 'pull_pork',\n",
       " 'crab leg': 'crab_leg',\n",
       " 'whi whi': 'whi_whi',\n",
       " 'last week': 'last_week',\n",
       " 'though not': 'though_not',\n",
       " 'decid go': 'decid_go',\n",
       " 'make feel': 'make_feel',\n",
       " 'so nice': 'so_nice',\n",
       " 'fine but': 'fine_but',\n",
       " 'veri attent': 'veri_attent',\n",
       " 'give anoth': 'give_anoth',\n",
       " 'veri rude': 'veri_rude',\n",
       " 'anyth els': 'anyth_els',\n",
       " 'coupl time': 'coupl_time',\n",
       " 'veri small': 'veri_small',\n",
       " 'month ago': 'month_ago',\n",
       " 'top notch': 'top_notch',\n",
       " 'one person': 'one_person',\n",
       " 'follow up': 'follow_up',\n",
       " 'place veri': 'place_veri',\n",
       " 'want get': 'want_get',\n",
       " 'not abl': 'not_abl',\n",
       " 'but like': 'but_like',\n",
       " 'review but': 'review_but',\n",
       " 'spring roll': 'spring_roll',\n",
       " 'food pretti': 'food_pretti',\n",
       " 'onion ring': 'onion_ring',\n",
       " 'too sweet': 'too_sweet',\n",
       " 'hot sauc': 'hot_sauc',\n",
       " 'tell us': 'tell_us',\n",
       " 'gluten free': 'gluten_free',\n",
       " 'hit miss': 'hit_miss',\n",
       " 'take time': 'take_time',\n",
       " 'bad servic': 'bad_servic',\n",
       " 'get back': 'get_back',\n",
       " 'someth els': 'someth_els',\n",
       " 'so ask': 'so_ask',\n",
       " 'food qualiti': 'food_qualiti',\n",
       " 'just go': 'just_go',\n",
       " 'staff not': 'staff_not',\n",
       " 'all good': 'all_good',\n",
       " 'bad bebecaus': 'bad_bebecaus',\n",
       " 'nice place': 'nice_place',\n",
       " 'not tell': 'not_tell',\n",
       " 'no way': 'no_way',\n",
       " 'never again': 'never_again',\n",
       " 'get drink': 'get_drink',\n",
       " 'restaur but': 'restaur_but',\n",
       " 'got home': 'got_home',\n",
       " 'time tri': 'time_tri',\n",
       " 'just okay': 'just_okay',\n",
       " 'veri reason': 'veri_reason',\n",
       " 'dine room': 'dine_room',\n",
       " 'ask whi': 'ask_whi',\n",
       " 'so no': 'so_no',\n",
       " 'time food': 'time_food',\n",
       " 'last year': 'last_year',\n",
       " 'servic friend': 'servic_friend',\n",
       " 'chip salsa': 'chip_salsa',\n",
       " 'lunch special': 'lunch_special',\n",
       " 'peopl work': 'peopl_work',\n",
       " 'so order': 'so_order',\n",
       " 'took order': 'took_order',\n",
       " 'all eat': 'all_eat',\n",
       " 'up not': 'up_not',\n",
       " 'servic but': 'servic_but',\n",
       " 'not place': 'not_place',\n",
       " 'food realli': 'food_realli',\n",
       " 'menu item': 'menu_item',\n",
       " 'but again': 'but_again',\n",
       " 'great time': 'great_time',\n",
       " 'know not': 'know_not',\n",
       " 'wait min': 'wait_min',\n",
       " 'okay but': 'okay_but',\n",
       " 'howev not': 'howev_not',\n",
       " 'place good': 'place_good',\n",
       " 'veri busi': 'veri_busi',\n",
       " 'look great': 'look_great',\n",
       " 'first all': 'first_all',\n",
       " 'but got': 'but_got',\n",
       " 'amaz but': 'amaz_but',\n",
       " 'so disappoint': 'so_disappoint',\n",
       " 'servic excel': 'servic_excel',\n",
       " 'alway good': 'alway_good',\n",
       " 'so go': 'so_go',\n",
       " 'come again': 'come_again',\n",
       " 'one day': 'one_day',\n",
       " 'pleasant surpris': 'pleasant_surpris',\n",
       " 'not not': 'not_not',\n",
       " 'food place': 'food_place',\n",
       " 'ask us': 'ask_us',\n",
       " 'get order': 'get_order',\n",
       " 'greet by': 'greet_by',\n",
       " 'abl get': 'abl_get',\n",
       " 'food alway': 'food_alway',\n",
       " 'groceri store': 'groceri_store',\n",
       " 'sign up': 'sign_up',\n",
       " 'clean up': 'clean_up',\n",
       " 'no flavor': 'no_flavor',\n",
       " 'littl too': 'littl_too',\n",
       " 'down street': 'down_street',\n",
       " 'decent but': 'decent_but',\n",
       " 'last visit': 'last_visit',\n",
       " 'not busi': 'not_busi',\n",
       " 'one not': 'one_not',\n",
       " 'check us': 'check_us',\n",
       " 'beer select': 'beer_select',\n",
       " 'all veri': 'all_veri',\n",
       " 'go wrong': 'go_wrong',\n",
       " 'veri happi': 'veri_happi',\n",
       " 'open up': 'open_up',\n",
       " 'go somewher': 'go_somewher',\n",
       " 'like but': 'like_but',\n",
       " 'hour later': 'hour_later',\n",
       " 'tasti but': 'tasti_but',\n",
       " 'no matter': 'no_matter',\n",
       " 'ok not': 'ok_not',\n",
       " 'mayb just': 'mayb_just',\n",
       " 'hand down': 'hand_down',\n",
       " 'place realli': 'place_realli',\n",
       " 'french fri': 'french_fri',\n",
       " 'bar area': 'bar_area',\n",
       " 'food amaz': 'food_amaz',\n",
       " 'everi singl': 'everi_singl',\n",
       " 'three time': 'three_time',\n",
       " 'all great': 'all_great',\n",
       " 'place tri': 'place_tri',\n",
       " 'took forev': 'took_forev',\n",
       " 'friend not': 'friend_not',\n",
       " 'made feel': 'made_feel',\n",
       " 'just so': 'just_so',\n",
       " 'not fan': 'not_fan',\n",
       " 'yelp review': 'yelp_review',\n",
       " 'even more': 'even_more',\n",
       " 'alway get': 'alway_get',\n",
       " 'way better': 'way_better',\n",
       " 'up get': 'up_get',\n",
       " 'pork belli': 'pork_belli',\n",
       " 'no not': 'no_not',\n",
       " 'never come': 'never_come',\n",
       " 'long line': 'long_line',\n",
       " 'bebecaus so': 'bebecaus_so',\n",
       " 'order drink': 'order_drink',\n",
       " 'how mani': 'how_mani',\n",
       " 'day later': 'day_later',\n",
       " 'tri someth': 'tri_someth',\n",
       " 'price reason': 'price_reason',\n",
       " 'recommend anyon': 'recommend_anyon',\n",
       " 'all around': 'all_around',\n",
       " 'also got': 'also_got',\n",
       " 'two peopl': 'two_peopl',\n",
       " 'more time': 'more_time',\n",
       " 'by way': 'by_way',\n",
       " 'multipl time': 'multipl_time',\n",
       " 'anywher els': 'anywher_els',\n",
       " 'deep fri': 'deep_fri',\n",
       " 'right next': 'right_next',\n",
       " 'best thing': 'best_thing',\n",
       " 'not quit': 'not_quit',\n",
       " 'time just': 'time_just',\n",
       " 'get one': 'get_one',\n",
       " 'more expens': 'more_expens',\n",
       " 'servic slow': 'servic_slow',\n",
       " 'wait food': 'wait_food',\n",
       " 'fish taco': 'fish_taco',\n",
       " 'car wash': 'car_wash',\n",
       " 'carn asada': 'carn_asada',\n",
       " 'menu not': 'menu_not',\n",
       " 'get better': 'get_better',\n",
       " 'realli great': 'realli_great',\n",
       " 'made sure': 'made_sure',\n",
       " 'how long': 'how_long',\n",
       " 'noodl soup': 'noodl_soup',\n",
       " 'veri much': 'veri_much',\n",
       " 'servic alway': 'servic_alway',\n",
       " 'chicken sandwich': 'chicken_sandwich',\n",
       " 'price but': 'price_but',\n",
       " 'never return': 'never_return',\n",
       " 'just got': 'just_got',\n",
       " 'time got': 'time_got',\n",
       " 'give bad': 'give_bad',\n",
       " 'per person': 'per_person',\n",
       " 'go not': 'go_not',\n",
       " 'by say': 'by_say',\n",
       " 'bad review': 'bad_review',\n",
       " 'hard find': 'hard_find',\n",
       " 'good job': 'good_job',\n",
       " 'servic so': 'servic_so',\n",
       " 'food court': 'food_court',\n",
       " 'short rib': 'short_rib',\n",
       " 'let us': 'let_us',\n",
       " 'tabl not': 'tabl_not',\n",
       " 'took time': 'took_time'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findBigrams = {}\n",
    "for bg in top_bigrams:\n",
    "    key = bg[0]+\" \"+bg[1]\n",
    "    findBigrams[key] = bg[0]+\"_\"+bg[1]\n",
    "\n",
    "findBigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tagged</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>no_nouns</th>\n",
       "      <th>no_nouns_stemmed</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>trying to have a nice quiet dinner.  the annou...</td>\n",
       "      <td>tri nice quiet dinner announc award giveaway w...</td>\n",
       "      <td>[trying, nice, quiet, dinner, announcer, award...</td>\n",
       "      <td>[(trying, VBG), (nice, JJ), (quiet, JJ), (dinn...</td>\n",
       "      <td>[nice, quiet, loud]</td>\n",
       "      <td>[dinner, announcer, awards, way, restaurant]</td>\n",
       "      <td>[trying, nice, quiet, giveaways, too, loud]</td>\n",
       "      <td>[tri, nice, quiet, giveaway, too, loud]</td>\n",
       "      <td>[tri, nice, quiet, dinner, announc, award, giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Been getting food to go from here for over 3yr...</td>\n",
       "      <td>get food go yrs wife usual tend get item whi f...</td>\n",
       "      <td>[getting, food, go, yrs, wife, usually, tend, ...</td>\n",
       "      <td>[(getting, VBG), (food, NN), (go, VB), (yrs, J...</td>\n",
       "      <td>[yrs, mongolian, special, noodle, best, chines...</td>\n",
       "      <td>[food, wife, items, something, works, beef, lu...</td>\n",
       "      <td>[getting, go, yrs, usually, tend, get, why, fi...</td>\n",
       "      <td>[get, go, yrs, usual, tend, get, whi, fix, alw...</td>\n",
       "      <td>[get, food, go, yrs, wife, usual, tend, get, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ugh. I've had to eat here a couple of times be...</td>\n",
       "      <td>ugh eat coupl time bebecaus work event cours m...</td>\n",
       "      <td>[ugh, eat, couple, times, bebecause, work, eve...</td>\n",
       "      <td>[(ugh, JJ), (eat, NN), (couple, NN), (times, N...</td>\n",
       "      <td>[ugh, clad, super, much, salad, sure, helpful,...</td>\n",
       "      <td>[eat, couple, times, work, events, course, gir...</td>\n",
       "      <td>[ugh, bebecause, makes, snotily, clad, super, ...</td>\n",
       "      <td>[ugh, bebecaus, make, snotili, clad, super, aw...</td>\n",
       "      <td>[ugh, eat, coupl, time, bebecaus, work, event,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The people here are so nice! I ordered on eat ...</td>\n",
       "      <td>peopl so nice order eat prompt call doubl chec...</td>\n",
       "      <td>[people, so, nice, ordered, eat, promptly, cal...</td>\n",
       "      <td>[(people, NNS), (so, RB), (nice, JJ), (ordered...</td>\n",
       "      <td>[nice, double, sweet]</td>\n",
       "      <td>[people, eat, check, everything]</td>\n",
       "      <td>[so, nice, ordered, promptly, called, double, ...</td>\n",
       "      <td>[so, nice, order, prompt, call, doubl, correct...</td>\n",
       "      <td>[peopl, so, nice, order, eat, prompt, call, do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard alot of good things about this place and...</td>\n",
       "      <td>heard alot good thing place decid grab breakfa...</td>\n",
       "      <td>[heard, alot, good, things, place, decided, gr...</td>\n",
       "      <td>[(heard, NN), (alot, NN), (good, JJ), (things,...</td>\n",
       "      <td>[good, cheese, large, hungry, hot, green, def]</td>\n",
       "      <td>[heard, alot, things, place, grab, breakfast, ...</td>\n",
       "      <td>[good, decided, say, enjoyed, cheese, firstly,...</td>\n",
       "      <td>[good, decid, say, enjoy, chees, first, rather...</td>\n",
       "      <td>[heard, alot, good, thing, place, decid, grab,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0    NaN  trying to have a nice quiet dinner.  the annou...   \n",
       "1    NaN  Been getting food to go from here for over 3yr...   \n",
       "2    NaN  Ugh. I've had to eat here a couple of times be...   \n",
       "3    NaN  The people here are so nice! I ordered on eat ...   \n",
       "4    NaN  Heard alot of good things about this place and...   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  tri nice quiet dinner announc award giveaway w...   \n",
       "1  get food go yrs wife usual tend get item whi f...   \n",
       "2  ugh eat coupl time bebecaus work event cours m...   \n",
       "3  peopl so nice order eat prompt call doubl chec...   \n",
       "4  heard alot good thing place decid grab breakfa...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [trying, nice, quiet, dinner, announcer, award...   \n",
       "1  [getting, food, go, yrs, wife, usually, tend, ...   \n",
       "2  [ugh, eat, couple, times, bebecause, work, eve...   \n",
       "3  [people, so, nice, ordered, eat, promptly, cal...   \n",
       "4  [heard, alot, good, things, place, decided, gr...   \n",
       "\n",
       "                                          pos_tagged  \\\n",
       "0  [(trying, VBG), (nice, JJ), (quiet, JJ), (dinn...   \n",
       "1  [(getting, VBG), (food, NN), (go, VB), (yrs, J...   \n",
       "2  [(ugh, JJ), (eat, NN), (couple, NN), (times, N...   \n",
       "3  [(people, NNS), (so, RB), (nice, JJ), (ordered...   \n",
       "4  [(heard, NN), (alot, NN), (good, JJ), (things,...   \n",
       "\n",
       "                                          adjectives  \\\n",
       "0                                [nice, quiet, loud]   \n",
       "1  [yrs, mongolian, special, noodle, best, chines...   \n",
       "2  [ugh, clad, super, much, salad, sure, helpful,...   \n",
       "3                              [nice, double, sweet]   \n",
       "4     [good, cheese, large, hungry, hot, green, def]   \n",
       "\n",
       "                                               nouns  \\\n",
       "0       [dinner, announcer, awards, way, restaurant]   \n",
       "1  [food, wife, items, something, works, beef, lu...   \n",
       "2  [eat, couple, times, work, events, course, gir...   \n",
       "3                   [people, eat, check, everything]   \n",
       "4  [heard, alot, things, place, grab, breakfast, ...   \n",
       "\n",
       "                                            no_nouns  \\\n",
       "0        [trying, nice, quiet, giveaways, too, loud]   \n",
       "1  [getting, go, yrs, usually, tend, get, why, fi...   \n",
       "2  [ugh, bebecause, makes, snotily, clad, super, ...   \n",
       "3  [so, nice, ordered, promptly, called, double, ...   \n",
       "4  [good, decided, say, enjoyed, cheese, firstly,...   \n",
       "\n",
       "                                    no_nouns_stemmed  \\\n",
       "0            [tri, nice, quiet, giveaway, too, loud]   \n",
       "1  [get, go, yrs, usual, tend, get, whi, fix, alw...   \n",
       "2  [ugh, bebecaus, make, snotili, clad, super, aw...   \n",
       "3  [so, nice, order, prompt, call, doubl, correct...   \n",
       "4  [good, decid, say, enjoy, chees, first, rather...   \n",
       "\n",
       "                                      tokens_stemmed  \n",
       "0  [tri, nice, quiet, dinner, announc, award, giv...  \n",
       "1  [get, food, go, yrs, wife, usual, tend, get, i...  \n",
       "2  [ugh, eat, coupl, time, bebecaus, work, event,...  \n",
       "3  [peopl, so, nice, order, eat, prompt, call, do...  \n",
       "4  [heard, alot, good, thing, place, decid, grab,...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_text(token_list):\n",
    "    string = ''\n",
    "    for token in token_list:\n",
    "        string += token + ' '\n",
    "    return string\n",
    "\n",
    "all_data['text_processed'] = all_data.tokens_stemmed.apply(to_text)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trigram, repl in findTrigrams.items():\n",
    "    all_data['text_processed'] = all_data.text_processed.str.replace(trigram, repl) \n",
    "    \n",
    "for bigram, repl in findBigrams.items():\n",
    "    all_data['text_processed'] = all_data.text_processed.str.replace(bigram, repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tagged</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>no_nouns</th>\n",
       "      <th>no_nouns_stemmed</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>trying to have a nice quiet dinner.  the annou...</td>\n",
       "      <td>tri nice quiet dinner announc award giveaway w...</td>\n",
       "      <td>[trying, nice, quiet, dinner, announcer, award...</td>\n",
       "      <td>[(trying, VBG), (nice, JJ), (quiet, JJ), (dinn...</td>\n",
       "      <td>[nice, quiet, loud]</td>\n",
       "      <td>[dinner, announcer, awards, way, restaurant]</td>\n",
       "      <td>[trying, nice, quiet, giveaways, too, loud]</td>\n",
       "      <td>[tri, nice, quiet, giveaway, too, loud]</td>\n",
       "      <td>[tri, nice, quiet, dinner, announc, award, giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Been getting food to go from here for over 3yr...</td>\n",
       "      <td>get_food go yrs wife usual tend get item whi f...</td>\n",
       "      <td>[getting, food, go, yrs, wife, usually, tend, ...</td>\n",
       "      <td>[(getting, VBG), (food, NN), (go, VB), (yrs, J...</td>\n",
       "      <td>[yrs, mongolian, special, noodle, best, chines...</td>\n",
       "      <td>[food, wife, items, something, works, beef, lu...</td>\n",
       "      <td>[getting, go, yrs, usually, tend, get, why, fi...</td>\n",
       "      <td>[get, go, yrs, usual, tend, get, whi, fix, alw...</td>\n",
       "      <td>[get, food, go, yrs, wife, usual, tend, get, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ugh. I've had to eat here a couple of times be...</td>\n",
       "      <td>ugh eat coupl_time bebecaus work event cours m...</td>\n",
       "      <td>[ugh, eat, couple, times, bebecause, work, eve...</td>\n",
       "      <td>[(ugh, JJ), (eat, NN), (couple, NN), (times, N...</td>\n",
       "      <td>[ugh, clad, super, much, salad, sure, helpful,...</td>\n",
       "      <td>[eat, couple, times, work, events, course, gir...</td>\n",
       "      <td>[ugh, bebecause, makes, snotily, clad, super, ...</td>\n",
       "      <td>[ugh, bebecaus, make, snotili, clad, super, aw...</td>\n",
       "      <td>[ugh, eat, coupl, time, bebecaus, work, event,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The people here are so nice! I ordered on eat ...</td>\n",
       "      <td>peopl so_nice order eat prompt call doubl chec...</td>\n",
       "      <td>[people, so, nice, ordered, eat, promptly, cal...</td>\n",
       "      <td>[(people, NNS), (so, RB), (nice, JJ), (ordered...</td>\n",
       "      <td>[nice, double, sweet]</td>\n",
       "      <td>[people, eat, check, everything]</td>\n",
       "      <td>[so, nice, ordered, promptly, called, double, ...</td>\n",
       "      <td>[so, nice, order, prompt, call, doubl, correct...</td>\n",
       "      <td>[peopl, so, nice, order, eat, prompt, call, do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard alot of good things about this place and...</td>\n",
       "      <td>heard alot good_thing place decid grab breakfa...</td>\n",
       "      <td>[heard, alot, good, things, place, decided, gr...</td>\n",
       "      <td>[(heard, NN), (alot, NN), (good, JJ), (things,...</td>\n",
       "      <td>[good, cheese, large, hungry, hot, green, def]</td>\n",
       "      <td>[heard, alot, things, place, grab, breakfast, ...</td>\n",
       "      <td>[good, decided, say, enjoyed, cheese, firstly,...</td>\n",
       "      <td>[good, decid, say, enjoy, chees, first, rather...</td>\n",
       "      <td>[heard, alot, good, thing, place, decid, grab,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0    NaN  trying to have a nice quiet dinner.  the annou...   \n",
       "1    NaN  Been getting food to go from here for over 3yr...   \n",
       "2    NaN  Ugh. I've had to eat here a couple of times be...   \n",
       "3    NaN  The people here are so nice! I ordered on eat ...   \n",
       "4    NaN  Heard alot of good things about this place and...   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  tri nice quiet dinner announc award giveaway w...   \n",
       "1  get_food go yrs wife usual tend get item whi f...   \n",
       "2  ugh eat coupl_time bebecaus work event cours m...   \n",
       "3  peopl so_nice order eat prompt call doubl chec...   \n",
       "4  heard alot good_thing place decid grab breakfa...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [trying, nice, quiet, dinner, announcer, award...   \n",
       "1  [getting, food, go, yrs, wife, usually, tend, ...   \n",
       "2  [ugh, eat, couple, times, bebecause, work, eve...   \n",
       "3  [people, so, nice, ordered, eat, promptly, cal...   \n",
       "4  [heard, alot, good, things, place, decided, gr...   \n",
       "\n",
       "                                          pos_tagged  \\\n",
       "0  [(trying, VBG), (nice, JJ), (quiet, JJ), (dinn...   \n",
       "1  [(getting, VBG), (food, NN), (go, VB), (yrs, J...   \n",
       "2  [(ugh, JJ), (eat, NN), (couple, NN), (times, N...   \n",
       "3  [(people, NNS), (so, RB), (nice, JJ), (ordered...   \n",
       "4  [(heard, NN), (alot, NN), (good, JJ), (things,...   \n",
       "\n",
       "                                          adjectives  \\\n",
       "0                                [nice, quiet, loud]   \n",
       "1  [yrs, mongolian, special, noodle, best, chines...   \n",
       "2  [ugh, clad, super, much, salad, sure, helpful,...   \n",
       "3                              [nice, double, sweet]   \n",
       "4     [good, cheese, large, hungry, hot, green, def]   \n",
       "\n",
       "                                               nouns  \\\n",
       "0       [dinner, announcer, awards, way, restaurant]   \n",
       "1  [food, wife, items, something, works, beef, lu...   \n",
       "2  [eat, couple, times, work, events, course, gir...   \n",
       "3                   [people, eat, check, everything]   \n",
       "4  [heard, alot, things, place, grab, breakfast, ...   \n",
       "\n",
       "                                            no_nouns  \\\n",
       "0        [trying, nice, quiet, giveaways, too, loud]   \n",
       "1  [getting, go, yrs, usually, tend, get, why, fi...   \n",
       "2  [ugh, bebecause, makes, snotily, clad, super, ...   \n",
       "3  [so, nice, ordered, promptly, called, double, ...   \n",
       "4  [good, decided, say, enjoyed, cheese, firstly,...   \n",
       "\n",
       "                                    no_nouns_stemmed  \\\n",
       "0            [tri, nice, quiet, giveaway, too, loud]   \n",
       "1  [get, go, yrs, usual, tend, get, whi, fix, alw...   \n",
       "2  [ugh, bebecaus, make, snotili, clad, super, aw...   \n",
       "3  [so, nice, order, prompt, call, doubl, correct...   \n",
       "4  [good, decid, say, enjoy, chees, first, rather...   \n",
       "\n",
       "                                      tokens_stemmed  \n",
       "0  [tri, nice, quiet, dinner, announc, award, giv...  \n",
       "1  [get, food, go, yrs, wife, usual, tend, get, i...  \n",
       "2  [ugh, eat, coupl, time, bebecaus, work, event,...  \n",
       "3  [peopl, so, nice, order, eat, prompt, call, do...  \n",
       "4  [heard, alot, good, thing, place, decid, grab,...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # making variants of the pre-processing so far\n",
    "\n",
    "# def n_gram(tokens_no_stopwords, ngram_corpus):\n",
    "#     return [x for x in ngram_corpus if x not in tokens_no_stopwords]\n",
    "\n",
    "# all_data['only_ngrams'] = all_data.apply(lambda x: n_gram(x.tokens, x.n_grams), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data['tokens_ngrams'] = all_data[\"tokens\"] + all_data[\"only_ngrams\"] \n",
    "# all_data[\"ngrams_adjectives\"] = all_data[\"n_grams\"] + all_data[\"adjectives\"]\n",
    "\n",
    "# all_data_1 = all_data[[\"text\", 'tokens_ngrams','ngrams_adjectives',\"label\"]]\n",
    "# all_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tagged</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>no_nouns</th>\n",
       "      <th>no_nouns_stemmed</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>trying to have a nice quiet dinner.  the annou...</td>\n",
       "      <td>tri nice quiet dinner announc award giveaway w...</td>\n",
       "      <td>[tri, nice, quiet, dinner, announc, award, giv...</td>\n",
       "      <td>[(trying, VBG), (nice, JJ), (quiet, JJ), (dinn...</td>\n",
       "      <td>[nice, quiet, loud]</td>\n",
       "      <td>[dinner, announcer, awards, way, restaurant]</td>\n",
       "      <td>[trying, nice, quiet, giveaways, too, loud]</td>\n",
       "      <td>[tri, nice, quiet, giveaway, too, loud]</td>\n",
       "      <td>[tri, nice, quiet, dinner, announc, award, giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Been getting food to go from here for over 3yr...</td>\n",
       "      <td>get_food go yrs wife usual tend get item whi f...</td>\n",
       "      <td>[get_food, go, yrs, wife, usual, tend, get, it...</td>\n",
       "      <td>[(getting, VBG), (food, NN), (go, VB), (yrs, J...</td>\n",
       "      <td>[yrs, mongolian, special, noodle, best, chines...</td>\n",
       "      <td>[food, wife, items, something, works, beef, lu...</td>\n",
       "      <td>[getting, go, yrs, usually, tend, get, why, fi...</td>\n",
       "      <td>[get, go, yrs, usual, tend, get, whi, fix, alw...</td>\n",
       "      <td>[get, food, go, yrs, wife, usual, tend, get, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ugh. I've had to eat here a couple of times be...</td>\n",
       "      <td>ugh eat coupl_time bebecaus work event cours m...</td>\n",
       "      <td>[ugh, eat, coupl_time, bebecaus, work, event, ...</td>\n",
       "      <td>[(ugh, JJ), (eat, NN), (couple, NN), (times, N...</td>\n",
       "      <td>[ugh, clad, super, much, salad, sure, helpful,...</td>\n",
       "      <td>[eat, couple, times, work, events, course, gir...</td>\n",
       "      <td>[ugh, bebecause, makes, snotily, clad, super, ...</td>\n",
       "      <td>[ugh, bebecaus, make, snotili, clad, super, aw...</td>\n",
       "      <td>[ugh, eat, coupl, time, bebecaus, work, event,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The people here are so nice! I ordered on eat ...</td>\n",
       "      <td>peopl so_nice order eat prompt call doubl chec...</td>\n",
       "      <td>[peopl, so_nice, order, eat, prompt, call, dou...</td>\n",
       "      <td>[(people, NNS), (so, RB), (nice, JJ), (ordered...</td>\n",
       "      <td>[nice, double, sweet]</td>\n",
       "      <td>[people, eat, check, everything]</td>\n",
       "      <td>[so, nice, ordered, promptly, called, double, ...</td>\n",
       "      <td>[so, nice, order, prompt, call, doubl, correct...</td>\n",
       "      <td>[peopl, so, nice, order, eat, prompt, call, do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard alot of good things about this place and...</td>\n",
       "      <td>heard alot good_thing place decid grab breakfa...</td>\n",
       "      <td>[heard, alot, good_thing, place, decid, grab, ...</td>\n",
       "      <td>[(heard, NN), (alot, NN), (good, JJ), (things,...</td>\n",
       "      <td>[good, cheese, large, hungry, hot, green, def]</td>\n",
       "      <td>[heard, alot, things, place, grab, breakfast, ...</td>\n",
       "      <td>[good, decided, say, enjoyed, cheese, firstly,...</td>\n",
       "      <td>[good, decid, say, enjoy, chees, first, rather...</td>\n",
       "      <td>[heard, alot, good, thing, place, decid, grab,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0    NaN  trying to have a nice quiet dinner.  the annou...   \n",
       "1    NaN  Been getting food to go from here for over 3yr...   \n",
       "2    NaN  Ugh. I've had to eat here a couple of times be...   \n",
       "3    NaN  The people here are so nice! I ordered on eat ...   \n",
       "4    NaN  Heard alot of good things about this place and...   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  tri nice quiet dinner announc award giveaway w...   \n",
       "1  get_food go yrs wife usual tend get item whi f...   \n",
       "2  ugh eat coupl_time bebecaus work event cours m...   \n",
       "3  peopl so_nice order eat prompt call doubl chec...   \n",
       "4  heard alot good_thing place decid grab breakfa...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [tri, nice, quiet, dinner, announc, award, giv...   \n",
       "1  [get_food, go, yrs, wife, usual, tend, get, it...   \n",
       "2  [ugh, eat, coupl_time, bebecaus, work, event, ...   \n",
       "3  [peopl, so_nice, order, eat, prompt, call, dou...   \n",
       "4  [heard, alot, good_thing, place, decid, grab, ...   \n",
       "\n",
       "                                          pos_tagged  \\\n",
       "0  [(trying, VBG), (nice, JJ), (quiet, JJ), (dinn...   \n",
       "1  [(getting, VBG), (food, NN), (go, VB), (yrs, J...   \n",
       "2  [(ugh, JJ), (eat, NN), (couple, NN), (times, N...   \n",
       "3  [(people, NNS), (so, RB), (nice, JJ), (ordered...   \n",
       "4  [(heard, NN), (alot, NN), (good, JJ), (things,...   \n",
       "\n",
       "                                          adjectives  \\\n",
       "0                                [nice, quiet, loud]   \n",
       "1  [yrs, mongolian, special, noodle, best, chines...   \n",
       "2  [ugh, clad, super, much, salad, sure, helpful,...   \n",
       "3                              [nice, double, sweet]   \n",
       "4     [good, cheese, large, hungry, hot, green, def]   \n",
       "\n",
       "                                               nouns  \\\n",
       "0       [dinner, announcer, awards, way, restaurant]   \n",
       "1  [food, wife, items, something, works, beef, lu...   \n",
       "2  [eat, couple, times, work, events, course, gir...   \n",
       "3                   [people, eat, check, everything]   \n",
       "4  [heard, alot, things, place, grab, breakfast, ...   \n",
       "\n",
       "                                            no_nouns  \\\n",
       "0        [trying, nice, quiet, giveaways, too, loud]   \n",
       "1  [getting, go, yrs, usually, tend, get, why, fi...   \n",
       "2  [ugh, bebecause, makes, snotily, clad, super, ...   \n",
       "3  [so, nice, ordered, promptly, called, double, ...   \n",
       "4  [good, decided, say, enjoyed, cheese, firstly,...   \n",
       "\n",
       "                                    no_nouns_stemmed  \\\n",
       "0            [tri, nice, quiet, giveaway, too, loud]   \n",
       "1  [get, go, yrs, usual, tend, get, whi, fix, alw...   \n",
       "2  [ugh, bebecaus, make, snotili, clad, super, aw...   \n",
       "3  [so, nice, order, prompt, call, doubl, correct...   \n",
       "4  [good, decid, say, enjoy, chees, first, rather...   \n",
       "\n",
       "                                      tokens_stemmed  \n",
       "0  [tri, nice, quiet, dinner, announc, award, giv...  \n",
       "1  [get, food, go, yrs, wife, usual, tend, get, i...  \n",
       "2  [ugh, eat, coupl, time, bebecaus, work, event,...  \n",
       "3  [peopl, so, nice, order, eat, prompt, call, do...  \n",
       "4  [heard, alot, good, thing, place, decid, grab,...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize the data\n",
    "all_data[\"tokens\"] = all_data.text_processed.apply(tokenize)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making new data frame with dropped NA values \n",
    "labeled_data = all_data.dropna(axis = 0, how ='any')\n",
    "labeled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tagged</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>no_nouns</th>\n",
       "      <th>no_nouns_stemmed</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>4.0</td>\n",
       "      <td>The new rule is - \\r\\nif you are waiting for a...</td>\n",
       "      <td>new rule wait tabl almost alway not_wait insid...</td>\n",
       "      <td>[new, rule, wait, tabl, almost, alway, not_wai...</td>\n",
       "      <td>[(new, JJ), (rule, NN), (waiting, VBG), (table...</td>\n",
       "      <td>[new, sign, upfront, awful, cold, p, short, wr...</td>\n",
       "      <td>[rule, table, becauses, concerns, patrons, apo...</td>\n",
       "      <td>[new, waiting, almost, always, not, wait, insi...</td>\n",
       "      <td>[new, wait, almost, alway, not, wait, insid, j...</td>\n",
       "      <td>[new, rule, wait, tabl, almost, alway, not, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50001</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Flirted with giving this two stars, but that's...</td>\n",
       "      <td>flirt give_bad_but pretti damn rate might just...</td>\n",
       "      <td>[flirt, give_bad_but, pretti, damn, rate, migh...</td>\n",
       "      <td>[(flirted, VBN), (giving, VBG), (bad, JJ), (bu...</td>\n",
       "      <td>[bad, pretty, new, east, many, hidden, friend,...</td>\n",
       "      <td>[rating, night, side, gems, fiance, drinks, th...</td>\n",
       "      <td>[flirted, giving, bad, but, pretty, damning, m...</td>\n",
       "      <td>[flirt, give, bad, but, pretti, damn, might, j...</td>\n",
       "      <td>[flirt, give, bad, but, pretti, damn, rate, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50002</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I was staying at planet Hollywood across the s...</td>\n",
       "      <td>stay planet hollywood across_street saw good r...</td>\n",
       "      <td>[stay, planet, hollywood, across_street, saw, ...</td>\n",
       "      <td>[(staying, VBG), (planet, NN), (hollywood, NN)...</td>\n",
       "      <td>[good, give, good, bacon, cheese, cold, carame...</td>\n",
       "      <td>[planet, hollywood, street, reviews, try, brea...</td>\n",
       "      <td>[staying, across, saw, good, so, husband, deci...</td>\n",
       "      <td>[stay, across, saw, good, so, husband, decid, ...</td>\n",
       "      <td>[stay, planet, hollywood, across, street, saw,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50003</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Food is good but prices are super expensive.  ...</td>\n",
       "      <td>food_good_but price super expens buck extra la...</td>\n",
       "      <td>[food_good_but, price, super, expens, buck, ex...</td>\n",
       "      <td>[(food, NN), (good, JJ), (but, CC), (prices, N...</td>\n",
       "      <td>[good, expensive, large, carne, little, bigger...</td>\n",
       "      <td>[food, prices, bucks, asada, taco, bell, bean,...</td>\n",
       "      <td>[good, but, super, expensive, extra, large, li...</td>\n",
       "      <td>[good, but, super, expens, extra, larg, littl,...</td>\n",
       "      <td>[food, good, but, price, super, expens, buck, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50004</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Worse company to deal with they do horrible wo...</td>\n",
       "      <td>wors compani deal horribl work bring truck bac...</td>\n",
       "      <td>[wors, compani, deal, horribl, work, bring, tr...</td>\n",
       "      <td>[(worse, JJR), (company, NN), (deal, NN), (hor...</td>\n",
       "      <td>[worse, horrible, door, trim, straight, update...</td>\n",
       "      <td>[company, deal, work, truck, replacement, door...</td>\n",
       "      <td>[worse, horrible, back, not, match, trim, mold...</td>\n",
       "      <td>[wors, horribl, back, not, match, trim, mold, ...</td>\n",
       "      <td>[wors, compani, deal, horribl, work, bring, tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "50000    4.0  The new rule is - \\r\\nif you are waiting for a...   \n",
       "50001    3.0  Flirted with giving this two stars, but that's...   \n",
       "50002    5.0  I was staying at planet Hollywood across the s...   \n",
       "50003    2.0  Food is good but prices are super expensive.  ...   \n",
       "50004    1.0  Worse company to deal with they do horrible wo...   \n",
       "\n",
       "                                          text_processed  \\\n",
       "50000  new rule wait tabl almost alway not_wait insid...   \n",
       "50001  flirt give_bad_but pretti damn rate might just...   \n",
       "50002  stay planet hollywood across_street saw good r...   \n",
       "50003  food_good_but price super expens buck extra la...   \n",
       "50004  wors compani deal horribl work bring truck bac...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "50000  [new, rule, wait, tabl, almost, alway, not_wai...   \n",
       "50001  [flirt, give_bad_but, pretti, damn, rate, migh...   \n",
       "50002  [stay, planet, hollywood, across_street, saw, ...   \n",
       "50003  [food_good_but, price, super, expens, buck, ex...   \n",
       "50004  [wors, compani, deal, horribl, work, bring, tr...   \n",
       "\n",
       "                                              pos_tagged  \\\n",
       "50000  [(new, JJ), (rule, NN), (waiting, VBG), (table...   \n",
       "50001  [(flirted, VBN), (giving, VBG), (bad, JJ), (bu...   \n",
       "50002  [(staying, VBG), (planet, NN), (hollywood, NN)...   \n",
       "50003  [(food, NN), (good, JJ), (but, CC), (prices, N...   \n",
       "50004  [(worse, JJR), (company, NN), (deal, NN), (hor...   \n",
       "\n",
       "                                              adjectives  \\\n",
       "50000  [new, sign, upfront, awful, cold, p, short, wr...   \n",
       "50001  [bad, pretty, new, east, many, hidden, friend,...   \n",
       "50002  [good, give, good, bacon, cheese, cold, carame...   \n",
       "50003  [good, expensive, large, carne, little, bigger...   \n",
       "50004  [worse, horrible, door, trim, straight, update...   \n",
       "\n",
       "                                                   nouns  \\\n",
       "50000  [rule, table, becauses, concerns, patrons, apo...   \n",
       "50001  [rating, night, side, gems, fiance, drinks, th...   \n",
       "50002  [planet, hollywood, street, reviews, try, brea...   \n",
       "50003  [food, prices, bucks, asada, taco, bell, bean,...   \n",
       "50004  [company, deal, work, truck, replacement, door...   \n",
       "\n",
       "                                                no_nouns  \\\n",
       "50000  [new, waiting, almost, always, not, wait, insi...   \n",
       "50001  [flirted, giving, bad, but, pretty, damning, m...   \n",
       "50002  [staying, across, saw, good, so, husband, deci...   \n",
       "50003  [good, but, super, expensive, extra, large, li...   \n",
       "50004  [worse, horrible, back, not, match, trim, mold...   \n",
       "\n",
       "                                        no_nouns_stemmed  \\\n",
       "50000  [new, wait, almost, alway, not, wait, insid, j...   \n",
       "50001  [flirt, give, bad, but, pretti, damn, might, j...   \n",
       "50002  [stay, across, saw, good, so, husband, decid, ...   \n",
       "50003  [good, but, super, expens, extra, larg, littl,...   \n",
       "50004  [wors, horribl, back, not, match, trim, mold, ...   \n",
       "\n",
       "                                          tokens_stemmed  \n",
       "50000  [new, rule, wait, tabl, almost, alway, not, wa...  \n",
       "50001  [flirt, give, bad, but, pretti, damn, rate, mi...  \n",
       "50002  [stay, planet, hollywood, across, street, saw,...  \n",
       "50003  [food, good, but, price, super, expens, buck, ...  \n",
       "50004  [wors, compani, deal, horribl, work, bring, tr...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[no_tokens,'text_processed'] = 'hmm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('text_preprocessed', encoding='utf-8',index=False)\n",
    "labeled_data.to_csv('labeled_text_preprocessed', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
